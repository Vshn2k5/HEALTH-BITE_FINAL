# ğŸ—ºï¸ BUILD ORDER

```
Week 1 â€” Foundation:
  Day 1: app factory + config + extensions + DB connection
  Day 2: All models + migrations
  Day 3: Auth middleware + JWT login endpoint
  Day 4: RBAC middleware + audit middleware
  Day 5: Standard response + pagination utils

Week 2 â€” Core Pages:
  Day 1: Dashboard endpoints (Page 1)
  Day 2: Food Management endpoints (Page 2)
  Day 3: Inventory endpoints (Page 3)
  Day 4: Orders endpoints (Page 4)
  Day 5: Users endpoints (Page 5)

Week 3 â€” Intelligence Layer:
  Day 1-2: Analytics endpoints (Page 6) â€” most complex
  Day 3: AI Monitoring endpoints (Page 7)
  Day 4: Background retrain task
  Day 5: Polling status + metrics update

Week 4 â€” Reports + Audit + Polish:
  Day 1-2: Reports + export endpoints (Page 8)
  Day 3: Audit log endpoints (Page 9)
  Day 4: Rate limiting + security hardening
  Day 5: Integration testing all 9 pages
```




week 1 plans 

## ğŸ”· DAY 1 PROMPT â€” App Factory + Config + Extensions + DB Connection

```
Build the Day 1 foundation layer of a Flask backend
for an AI-Enabled Smart Canteen Admin System.

Day 1 covers ONLY these 4 things:
  1. App factory (app.py)
  2. Configuration (config.py)
  3. Extensions initialization (extensions.py)
  4. Database connection verification

Do NOT build any routes, models, or middleware today.
Just the clean foundation everything else will plug into.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ extensions.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 1 â€” config.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Create a Config class hierarchy:

class Config (base):
  SECRET_KEY = from env SECRET_KEY
  JWT_SECRET_KEY = from env JWT_SECRET_KEY
  JWT_ACCESS_TOKEN_EXPIRES = timedelta(hours=8)
  JWT_REFRESH_TOKEN_EXPIRES = timedelta(days=30)
  JWT_TOKEN_LOCATION = ['headers']
  JWT_HEADER_NAME = 'Authorization'
  JWT_HEADER_TYPE = 'Bearer'
  SQLALCHEMY_TRACK_MODIFICATIONS = False
  SQLALCHEMY_ECHO = False
  JSON_SORT_KEYS = False
  MAX_CONTENT_LENGTH = 16 * 1024 * 1024  â† 16MB max upload

class DevelopmentConfig(Config):
  DEBUG = True
  SQLALCHEMY_DATABASE_URI = from env DEV_DATABASE_URL
  SQLALCHEMY_ECHO = True  â† log SQL in dev

class ProductionConfig(Config):
  DEBUG = False
  SQLALCHEMY_DATABASE_URI = from env DATABASE_URL
  SQLALCHEMY_ECHO = False
  JWT_ACCESS_TOKEN_EXPIRES = timedelta(hours=4)
    â† shorter in production

class TestingConfig(Config):
  TESTING = True
  SQLALCHEMY_DATABASE_URI = from env TEST_DATABASE_URL
  SQLALCHEMY_ECHO = False
  JWT_ACCESS_TOKEN_EXPIRES = timedelta(minutes=5)

config_map = {
  'development': DevelopmentConfig,
  'production':  ProductionConfig,
  'testing':     TestingConfig,
  'default':     DevelopmentConfig
}

def get_config(env_name):
  """
  Called by app factory.
  Reads FLASK_ENV from environment.
  Returns correct config class.
  Defaults to DevelopmentConfig if unrecognized.
  """

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 2 â€” extensions.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Initialize all Flask extensions here WITHOUT
binding them to an app yet (use app factory pattern).

Extensions to initialize:

db = SQLAlchemy()
  â† database ORM

migrate = Migrate()
  â† database migrations

jwt = JWTManager()
  â† JWT token handling

cors = CORS()
  â† cross-origin requests

limiter = Limiter(
  key_func=get_remote_address,
  default_limits=["200 per day", "50 per hour"]
)
  â† rate limiting

Configure JWTManager callbacks:

@jwt.expired_token_loader
  Return JSON: { success: False,
    message: 'Token has expired', code: 'TOKEN_EXPIRED' }
  HTTP 401

@jwt.invalid_token_loader
  Return JSON: { success: False,
    message: 'Invalid token', code: 'TOKEN_INVALID' }
  HTTP 401

@jwt.unauthorized_loader
  Return JSON: { success: False,
    message: 'Authorization token required',
    code: 'TOKEN_MISSING' }
  HTTP 401

@jwt.revoked_token_loader
  Return JSON: { success: False,
    message: 'Token has been revoked',
    code: 'TOKEN_REVOKED' }
  HTTP 401

All JWT error responses must follow the same
JSON structure as the rest of the API.
Never return HTML error pages.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 3 â€” app.py (App Factory)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_app(env_name=None):
  """
  Flask application factory.
  Called by run.py and by tests.
  Never instantiate Flask app at module level.
  """

  Steps inside create_app():

  STEP 1 â€” Create Flask instance:
    app = Flask(__name__)
    Load config via get_config(env_name)
    app.config.from_object(config_object)

  STEP 2 â€” Initialize extensions with app:
    db.init_app(app)
    migrate.init_app(app, db)
    jwt.init_app(app)

    CORS setup:
      cors.init_app(app,
        resources={
          r'/api/*': {
            origins: from env ALLOWED_ORIGINS
              (comma-separated, split to list)
              default: ['http://localhost:5500',
                        'http://127.0.0.1:5500']
            methods: ['GET','POST','PUT','DELETE','OPTIONS']
            allow_headers: ['Content-Type','Authorization']
            supports_credentials: True
          }
        }
      )

    limiter.init_app(app)

  STEP 3 â€” Register blueprints:
    Leave this section as a clearly labeled placeholder:
    # â”€â”€â”€ BLUEPRINTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # from admin.dashboard.routes import dashboard_bp
    # app.register_blueprint(dashboard_bp,
    #   url_prefix='/api/admin')
    # ... add more as built day by day
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  STEP 4 â€” Register global error handlers:

    @app.errorhandler(400)
      Return: { success: False, message: 'Bad request' } 400

    @app.errorhandler(401)
      Return: { success: False, message: 'Unauthorized' } 401

    @app.errorhandler(403)
      Return: { success: False, message: 'Forbidden' } 403

    @app.errorhandler(404)
      Return: { success: False, message: 'Not found' } 404

    @app.errorhandler(405)
      Return: { success: False,
        message: 'Method not allowed' } 405

    @app.errorhandler(409)
      Return: { success: False, message: 'Conflict' } 409

    @app.errorhandler(422)
      Return: { success: False,
        message: 'Unprocessable entity' } 422

    @app.errorhandler(429)
      Return: { success: False,
        message: 'Too many requests. Slow down.' } 429

    @app.errorhandler(500)
      Log the full error with app.logger.error(str(e))
      Return: { success: False,
        message: 'Internal server error' } 500
      Never expose stack trace in response

    All error handlers return JSON â€” never HTML.

  STEP 5 â€” Register a health check route:

    @app.route('/api/health', methods=['GET'])
    def health_check():
      """
      Public endpoint â€” no auth required.
      Used to verify server + DB are running.
      """
      Try to execute a simple DB query:
        db.session.execute(text('SELECT 1'))
      If success:
        Return: {
          success: True,
          message: 'Server is running',
          environment: current config name,
          database: 'connected',
          timestamp: current UTC ISO string
        } 200
      If DB fails:
        Return: {
          success: False,
          message: 'Server running but DB unreachable',
          database: 'disconnected',
          timestamp: current UTC ISO string
        } 503

  STEP 6 â€” Return app instance

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 4 â€” run.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Entry point for development server.

import os
from app import create_app

env = os.getenv('FLASK_ENV', 'development')
app = create_app(env)

if __name__ == '__main__':
  port = int(os.getenv('PORT', 5000))
  debug = env == 'development'
  app.run(
    host='0.0.0.0',
    port=port,
    debug=debug
  )

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 5 â€” .env.example
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Create a .env.example showing all required
environment variables with placeholder values:

# Flask
FLASK_ENV=development
SECRET_KEY=your-super-secret-key-change-this
PORT=5000

# JWT
JWT_SECRET_KEY=your-jwt-secret-key-change-this

# Database
DEV_DATABASE_URL=postgresql://user:password@localhost:5432/canteen_dev
TEST_DATABASE_URL=postgresql://user:password@localhost:5432/canteen_test
DATABASE_URL=postgresql://user:password@localhost:5432/canteen_prod

# CORS
ALLOWED_ORIGINS=http://localhost:5500,http://127.0.0.1:5500

# Rate Limiting
RATELIMIT_STORAGE_URL=memory://

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 6 â€” requirements.txt
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Flask==3.0.0
Flask-JWT-Extended==4.6.0
Flask-SQLAlchemy==3.1.1
Flask-Migrate==4.0.5
Flask-CORS==4.0.0
Flask-Limiter==3.5.0
psycopg2-binary==2.9.9
python-dotenv==1.0.0
reportlab==4.1.0
gunicorn==21.2.0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION STEPS TO INCLUDE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After building all files, include a
README_DAY1.md with these exact steps
to verify everything works:

Step 1 â€” Install dependencies:
  pip install -r requirements.txt

Step 2 â€” Create .env from .env.example:
  cp .env.example .env
  Fill in real DB credentials

Step 3 â€” Create PostgreSQL database:
  createdb canteen_dev

Step 4 â€” Run server:
  python run.py

Step 5 â€” Test health endpoint:
  curl http://localhost:5000/api/health
  Expected: { success: true, database: 'connected' }

Step 6 â€” Test error handler:
  curl http://localhost:5000/api/nonexistent
  Expected: { success: false, message: 'Not found' }

Step 7 â€” Verify CORS headers:
  curl -H "Origin: http://localhost:5500"
    http://localhost:5000/api/health
  Expected: Access-Control-Allow-Origin header present

If all 7 pass: Day 1 complete. Ready for Day 2 models.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- App factory pattern strictly â€” no module-level app instance
- All config from environment variables â€” zero hardcoded values
- All error responses return JSON â€” never HTML
- Extensions initialized in extensions.py,
  bound to app in create_app() only
- CORS locked to specific origins â€” not wildcard *
- Health check must actually query DB â€” not just return 200
- JWT error callbacks must follow same response format
  as all other endpoints
- .env file must never be committed â€” .env.example only
- All files must have clear section comments
- No business logic in app.py â€” it is plumbing only
```

---


Here's the complete Day 2 prompt:

---

## ğŸ”· DAY 2 PROMPT â€” All Models + Migrations

```
Build the Day 2 models and migrations layer of a Flask
backend for an AI-Enabled Smart Canteen Admin System.

Day 1 foundation is already complete:
  app.py, config.py, extensions.py, run.py all exist.
  PostgreSQL database is connected and verified.

Day 2 covers ONLY:
  1. All SQLAlchemy model files
  2. Model relationships and constraints
  3. Model helper methods
  4. Migration setup and initial migration

Do NOT build any routes or middleware today.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ models/
     â”œâ”€â”€ __init__.py
     â”œâ”€â”€ user.py
     â”œâ”€â”€ food.py
     â”œâ”€â”€ inventory.py
     â”œâ”€â”€ order.py
     â”œâ”€â”€ order_item.py
     â”œâ”€â”€ audit_log.py
     â”œâ”€â”€ ai_log.py
     â””â”€â”€ training_history.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GLOBAL MODEL RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Every model must:
  - Use UUID primary keys generated server-side
      id = db.Column(UUID(as_uuid=True),
        primary_key=True,
        default=uuid.uuid4)
  - Never use auto-increment integers as PKs
  - Have a to_dict() method returning clean JSON-safe dict
      No raw UUID objects â€” convert to str
      No datetime objects â€” convert to ISO string
      No password hashes â€” never included
      No SQLAlchemy internal attributes
  - Have a __repr__ for debug readability
  - All string columns have explicit max lengths
  - All nullable columns explicitly marked nullable=True
  - All non-nullable columns explicitly marked nullable=False
  - Use db.Enum for all status/type/role columns
    (enforces values at DB level)

Import pattern in every model file:
  from extensions import db
  import uuid
  from datetime import datetime
  from sqlalchemy.dialects.postgresql import UUID, JSONB, ARRAY

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 1 â€” user.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class User(db.Model):
  __tablename__ = 'users'

  Columns:
    id              UUID PK default uuid4
    name            String(100) NOT NULL
    email           String(255) UNIQUE NOT NULL
    password_hash   String(255) NOT NULL
    role            Enum NOT NULL default 'USER'
      values: 'SUPER_ADMIN','MANAGER','ANALYST','USER'
    status          Enum NOT NULL default 'active'
      values: 'active','inactive'
    risk_level      Enum NOT NULL default 'low'
      values: 'low','moderate','high'
    risk_score      Integer default 0 NOT NULL
    conditions      ARRAY(String) nullable=True
      â† PostgreSQL text array
    dietary_prefs   ARRAY(String) nullable=True
    joined_at       DateTime default datetime.utcnow NOT NULL
    last_active     DateTime nullable=True
    created_by      UUID FK â†’ users.id nullable=True
      â† self-referential (who created this admin)

  Relationships:
    orders          â†’ Order (back_populates='user')
    audit_logs      â†’ AuditLog (back_populates='admin')
    ai_logs         â†’ AiRecommendationLog
                      (back_populates='user')
    training_runs   â†’ AiTrainingHistory
                      (back_populates='triggered_by_user')
    inventory_updates â†’ Inventory
                      (back_populates='updated_by_user')

  Methods:

    set_password(password):
      Hash password using werkzeug
        generate_password_hash(password)
      Store in self.password_hash

    check_password(password):
      Return werkzeug check_password_hash(
        self.password_hash, password)

    has_role(*roles):
      Return self.role in roles

    is_super_admin():
      Return self.role == 'SUPER_ADMIN'

    get_role_level():
      Return integer from role hierarchy:
        SUPER_ADMIN=4, MANAGER=3, ANALYST=2, USER=1

    to_dict(include_sensitive=False):
      Returns:
        id, name, email, role, status,
        risk_level, risk_score,
        conditions (list or []),
        dietary_prefs (list or []),
        joined_at (ISO string),
        last_active (ISO string or None)
      Never include: password_hash, created_by

    to_summary_dict():
      Returns minimal dict for dropdown lists:
        id, name, email, role

    __repr__:
      f"<User {self.email} [{self.role}]>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 2 â€” food.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FoodItem(db.Model):
  __tablename__ = 'food_items'

  Columns:
    id          UUID PK default uuid4
    name        String(100) NOT NULL
    category    Enum NOT NULL
      values: 'Meals','Snacks','Beverages','Desserts','Healthy'
    calories    Numeric(6,2) NOT NULL
    sugar       Numeric(6,2) NOT NULL
    protein     Numeric(6,2) NOT NULL
    fat         Numeric(6,2) default 0.0 NOT NULL
    image_url   Text nullable=True
    description Text nullable=True
    available   Boolean default True NOT NULL
    created_at  DateTime default utcnow NOT NULL
    updated_at  DateTime default utcnow
                  onupdate=datetime.utcnow NOT NULL

  Relationships:
    inventory   â†’ Inventory (back_populates='food',
                  uselist=False, cascade='all,delete-orphan')
      â† one food has one inventory row
    order_items â†’ OrderItem (back_populates='food')
    ai_logs     â†’ AiRecommendationLog
                  (back_populates='food')

  Methods:

    is_in_stock():
      If self.inventory is None: return False
      Return self.inventory.current_stock > 0

    get_stock():
      If self.inventory is None: return 0
      Return self.inventory.current_stock

    get_status():
      If not self.available: return 'unavailable'
      If not self.is_in_stock(): return 'out_of_stock'
      Return 'available'

    to_dict():
      Returns:
        id, name, category, calories, sugar,
        protein, fat, image_url, description,
        available, created_at (ISO), updated_at (ISO)
        status: self.get_status()
        stock: self.get_stock()
          (from inventory relationship if loaded)

    to_table_dict():
      Returns to_dict() + flattened inventory data
      Used for food management table rows

    __repr__:
      f"<FoodItem {self.name} [{self.category}]>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 3 â€” inventory.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Inventory(db.Model):
  __tablename__ = 'inventory'

  Columns:
    id              UUID PK default uuid4
    food_id         UUID FK â†’ food_items.id
                    NOT NULL UNIQUE
                    â† UNIQUE: one inventory row per food
    current_stock   Integer NOT NULL default 0
    reorder_level   Integer NOT NULL default 10
    last_updated    DateTime default utcnow NOT NULL
    updated_by      UUID FK â†’ users.id nullable=True

  Constraints:
    CheckConstraint: current_stock >= 0
    CheckConstraint: reorder_level > 0

  Relationships:
    food             â†’ FoodItem (back_populates='inventory')
    updated_by_user  â†’ User
                      (back_populates='inventory_updates')

  Methods:

    get_status():
      If self.current_stock == 0: return 'out_of_stock'
      If self.current_stock < self.reorder_level:
        return 'low'
      Return 'healthy'

    needs_restock():
      Return self.current_stock < self.reorder_level

    to_dict():
      Returns:
        id, food_id (str), current_stock,
        reorder_level, last_updated (ISO),
        status: self.get_status()
        food_name: self.food.name if loaded
        food_category: self.food.category if loaded

    __repr__:
      f"<Inventory food={self.food_id}
        stock={self.current_stock}>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 4 â€” order.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Order(db.Model):
  __tablename__ = 'orders'

  Columns:
    id                   UUID PK default uuid4
    order_number         String(20) UNIQUE NOT NULL
      â† format: ORD-00001, generated via classmethod
    user_id              UUID FK â†’ users.id NOT NULL
    status               Enum NOT NULL default 'pending'
      values: 'pending','completed','cancelled'
    total                Numeric(10,2) NOT NULL
    payment_method       Enum nullable=True
      values: 'Cash','UPI','Card'
    delivery_type        Enum nullable=True
      values: 'Dine-in','Takeaway'
    special_instructions Text nullable=True
    created_at           DateTime default utcnow NOT NULL
    updated_at           DateTime default utcnow
                           onupdate=utcnow NOT NULL

  Relationships:
    user    â†’ User (back_populates='orders')
    items   â†’ OrderItem (back_populates='order',
                cascade='all,delete-orphan')

  Class Methods:

    generate_order_number():
      Query MAX(order_number) from orders table
      Parse numeric part, increment by 1
      Return formatted string: f'ORD-{num:05d}'
      Thread-safe: wrap in try/except, fallback to
        f'ORD-{uuid4().hex[:5].upper()}'

  Methods:

    get_item_count():
      Return sum of all item quantities

    has_health_flags():
      Return any(item.health_flag for item in self.items)

    can_change_status(new_status):
      Valid transitions:
        pending â†’ completed: True
        pending â†’ cancelled: True
        completed â†’ anything: False
        cancelled â†’ anything: False
      Return Boolean

    to_dict():
      Returns:
        id, order_number, status, total,
        payment_method, delivery_type,
        special_instructions,
        created_at (ISO), updated_at (ISO),
        item_count: self.get_item_count(),
        has_health_flags: self.has_health_flags()

    to_full_dict():
      Returns to_dict() +
        customer: self.user.to_summary_dict()
        items: [item.to_dict() for item in self.items]

    __repr__:
      f"<Order {self.order_number} [{self.status}]>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 5 â€” order_item.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OrderItem(db.Model):
  __tablename__ = 'order_items'

  Columns:
    id          UUID PK default uuid4
    order_id    UUID FK â†’ orders.id NOT NULL
    food_id     UUID FK â†’ food_items.id NOT NULL
    qty         Integer NOT NULL
    unit_price  Numeric(8,2) NOT NULL
    subtotal    Numeric(10,2) NOT NULL
    health_flag Boolean default False NOT NULL

  Constraints:
    CheckConstraint: qty > 0
    CheckConstraint: unit_price >= 0
    CheckConstraint: subtotal >= 0

  Relationships:
    order â†’ Order (back_populates='items')
    food  â†’ FoodItem (back_populates='order_items')

  Methods:

    to_dict():
      Returns:
        id, order_id (str), food_id (str),
        qty, unit_price (float), subtotal (float),
        health_flag,
        food_name: self.food.name if loaded,
        food_category: self.food.category if loaded

    __repr__:
      f"<OrderItem order={self.order_id}
        food={self.food_id} qty={self.qty}>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 6 â€” audit_log.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AuditLog(db.Model):
  __tablename__ = 'admin_audit_logs'

  Columns:
    id             UUID PK default uuid4
    admin_id       UUID FK â†’ users.id nullable=True
      â† nullable: system-generated logs have no admin
    action_type    Enum NOT NULL
      values: 'CREATE','UPDATE','DELETE','LOGIN',
              'LOGOUT','EXPORT','RETRAIN','STATUS_CHANGE'
    target_table   String(50) nullable=True
    target_id      String(100) nullable=True
    summary        Text nullable=True
    payload        JSONB nullable=True
    payload_before JSONB nullable=True
    payload_after  JSONB nullable=True
    ip_address     String(45) nullable=True
    user_agent     Text nullable=True
    timestamp      DateTime default utcnow NOT NULL

  Indexes:
    Index on: admin_id
    Index on: action_type
    Index on: target_table
    Index on: timestamp
    Index on: ip_address

  Relationships:
    admin â†’ User (back_populates='audit_logs')

  Class Methods:

    create(admin_id, action_type, target_table=None,
           target_id=None, summary=None, payload=None,
           before=None, after=None,
           ip_address=None, user_agent=None):
      Build and insert a new log entry.
      auto_summary(action_type, target_table, target_id):
        If no summary provided, generate from params:
          'CREATE on foods (id: xxx)'
          'DELETE on users (id: xxx)'
      Commit to DB.
      If commit fails: rollback silently, log to
        app.logger â€” never raise (audit must not
        break the main request)

  Methods:

    to_dict():
      Returns:
        id, admin_id (str), action_type, target_table,
        target_id, summary, payload, payload_before,
        payload_after, ip_address,
        timestamp (ISO),
        admin_name: self.admin.name if loaded,
        admin_role: self.admin.role if loaded

    __repr__:
      f"<AuditLog {self.action_type}
        on {self.target_table} at {self.timestamp}>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 7 â€” ai_log.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AiRecommendationLog(db.Model):
  __tablename__ = 'ai_recommendation_logs'

  Columns:
    id           UUID PK default uuid4
    user_id      UUID FK â†’ users.id NOT NULL
    food_id      UUID FK â†’ food_items.id NOT NULL
    reason       Text nullable=True
    confidence   Numeric(5,2) nullable=True
      â† 0.00 to 100.00 (percentage)
    match_score  Integer nullable=True
      â† 0 to 100
    user_action  Enum NOT NULL default 'no_response'
      values: 'accepted','rejected','no_response'
    created_at   DateTime default utcnow NOT NULL

  Indexes:
    Index on: user_id
    Index on: food_id
    Index on: user_action
    Index on: created_at

  Relationships:
    user â†’ User (back_populates='ai_logs')
    food â†’ FoodItem (back_populates='ai_logs')

  Methods:

    get_confidence_level():
      If self.confidence > 85: return 'high'
      If self.confidence >= 60: return 'medium'
      Return 'low'

    to_dict():
      Returns:
        id, user_id (str), food_id (str),
        reason, confidence (float), match_score,
        user_action, created_at (ISO),
        confidence_level: self.get_confidence_level(),
        user_name: self.user.name if loaded,
        user_risk: self.user.risk_level if loaded,
        food_name: self.food.name if loaded,
        food_category: self.food.category if loaded

    __repr__:
      f"<AiRecommendationLog user={self.user_id}
        food={self.food_id} action={self.user_action}>"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL 8 â€” training_history.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AiModelStatus(db.Model):
  __tablename__ = 'ai_model_status'

  Columns:
    id                 UUID PK default uuid4
    status             Enum NOT NULL default 'active'
      values: 'active','degraded','retraining'
    version            String(20) nullable=True
    accuracy           Numeric(5,2) nullable=True
    precision_score    Numeric(5,4) nullable=True
    recall_score       Numeric(5,4) nullable=True
    f1_score           Numeric(5,4) nullable=True
    last_trained       DateTime nullable=True
    total_predictions  BigInteger default 0 NOT NULL
    updated_at         DateTime default utcnow
                         onupdate=utcnow NOT NULL

  Class Methods:

    get_current():
      Return first/only row (singleton pattern)
      SELECT * FROM ai_model_status LIMIT 1
      If no row: create default row and return it

  Methods:

    to_dict():
      Returns:
        id, status, version, accuracy (float),
        precision_score (float), recall_score (float),
        f1_score (float), total_predictions,
        last_trained (ISO or None),
        updated_at (ISO),
        metrics: {
          accuracy, precision, recall, f1
        }

class AiTrainingHistory(db.Model):
  __tablename__ = 'ai_training_history'

  Columns:
    id               UUID PK default uuid4
    triggered_by     UUID FK â†’ users.id nullable=True
    started_at       DateTime default utcnow NOT NULL
    ended_at         DateTime nullable=True
    duration_seconds Integer nullable=True
    accuracy_before  Numeric(5,2) nullable=True
    accuracy_after   Numeric(5,2) nullable=True
    status           Enum NOT NULL default 'in_progress'
      values: 'success','failed','in_progress'
    notes            Text nullable=True

  Relationships:
    triggered_by_user â†’ User
      (back_populates='training_runs')

  Methods:

    get_duration_formatted():
      If not self.duration_seconds: return 'N/A'
      Convert seconds to "Xm Ys" format

    get_accuracy_delta():
      If before and after both set:
        return round(after - before, 2)
      Return None

    to_dict():
      Returns:
        id, triggered_by (str), started_at (ISO),
        ended_at (ISO or None),
        duration: self.get_duration_formatted(),
        accuracy_before (float or None),
        accuracy_after (float or None),
        accuracy_delta: self.get_accuracy_delta(),
        status, notes,
        triggered_by_name:
          self.triggered_by_user.name if loaded

class AiFeatureImportance(db.Model):
  __tablename__ = 'ai_feature_importance'

  Columns:
    id            UUID PK default uuid4
    feature_name  String(100) NOT NULL
    importance    Numeric(5,4) NOT NULL
    model_version String(20) nullable=True
    recorded_at   DateTime default utcnow NOT NULL

  Methods:

    to_dict():
      Returns:
        id, feature_name, importance (float),
        model_version, recorded_at (ISO)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE â€” models/__init__.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Import all models here so Flask-Migrate
can discover them:

from .user import User
from .food import FoodItem
from .inventory import Inventory
from .order import Order
from .order_item import OrderItem
from .audit_log import AuditLog
from .ai_log import AiRecommendationLog
from .training_history import (
    AiModelStatus,
    AiTrainingHistory,
    AiFeatureImportance
)

__all__ = [
    'User', 'FoodItem', 'Inventory',
    'Order', 'OrderItem', 'AuditLog',
    'AiRecommendationLog', 'AiModelStatus',
    'AiTrainingHistory', 'AiFeatureImportance'
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
UPDATE app.py FOR MODEL DISCOVERY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inside create_app(), after extensions init,
add this import block so migrate can see models:

  with app.app_context():
    import models  # noqa: F401
    â† This makes Flask-Migrate discover all tables

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MIGRATION COMMANDS TO DOCUMENT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

After all model files are created, include
a README_DAY2.md with exact commands:

Step 1 â€” Initialize migrations folder:
  flask db init
  â† Only run ONCE ever. Creates migrations/ folder.

Step 2 â€” Generate initial migration:
  flask db migrate -m "Initial schema â€” all tables"
  â† Inspects models, generates migration file.
  â† Review the generated file before proceeding.

Step 3 â€” Apply migration to database:
  flask db upgrade
  â† Creates all tables in PostgreSQL.

Step 4 â€” Verify tables created:
  psql canteen_dev -c "\dt"
  Expected tables:
    admin_audit_logs
    ai_feature_importance
    ai_model_status
    ai_recommendation_logs
    ai_training_history
    food_items
    inventory
    order_items
    orders
    users
    alembic_version

Step 5 â€” Verify foreign keys:
  psql canteen_dev -c "
    SELECT tc.table_name, kcu.column_name,
      ccu.table_name AS foreign_table
    FROM information_schema.table_constraints tc
    JOIN information_schema.key_column_usage kcu
      ON tc.constraint_name = kcu.constraint_name
    JOIN information_schema.constraint_column_usage ccu
      ON ccu.constraint_name = tc.constraint_name
    WHERE tc.constraint_type = 'FOREIGN KEY';"
  Verify all 9 foreign key relationships appear.

Step 6 â€” Seed one test admin user:
  flask shell
  >>> from models import User
  >>> from extensions import db
  >>> admin = User(
  ...   name='Super Admin',
  ...   email='admin@canteen.com',
  ...   role='SUPER_ADMIN'
  ... )
  >>> admin.set_password('Admin@123')
  >>> db.session.add(admin)
  >>> db.session.commit()
  >>> print(admin.to_dict())

Step 7 â€” Verify seed:
  psql canteen_dev -c "SELECT name, email, role
    FROM users;"

If all 7 pass: Day 2 complete. Ready for Day 3 auth.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- UUID primary keys on every model â€” no integers
- All Enums defined at DB level via db.Enum()
  so invalid values are rejected at database layer
- All to_dict() methods return only JSON-safe types:
    str, int, float, bool, list, dict, None
    Never UUID objects, datetime objects,
    SQLAlchemy objects, or Decimal objects
- Decimal columns â†’ convert to float in to_dict()
- DateTime columns â†’ .isoformat() + 'Z' suffix
- ARRAY columns â†’ return as list, default to []
  if None rather than returning None
- password_hash NEVER appears in any to_dict()
- Relationships use lazy='select' (default)
  unless specified otherwise
- All CheckConstraints named explicitly
  (easier debugging in PostgreSQL logs)
- AuditLog.create() must never raise an exception â€”
  wrap entire method in try/except
- Models import from extensions import db
  NEVER from app import db (circular import prevention)
- No business logic beyond simple computed properties
  in model files â€” complex logic belongs in services/
```

---


## ğŸ”· DAY 3 PROMPT â€” Auth Middleware + JWT Login Endpoint

```
Build the Day 3 authentication layer of a Flask backend
for an AI-Enabled Smart Canteen Admin System.

Days 1 and 2 are complete:
  app.py, config.py, extensions.py exist.
  All models exist and migrations applied.
  One SUPER_ADMIN user seeded in database.

Day 3 covers ONLY:
  1. Auth middleware (JWT verification)
  2. RBAC middleware (role enforcement)
  3. Login endpoint
  4. Logout endpoint
  5. Token refresh endpoint
  6. Get current admin endpoint
  7. Change own password endpoint

Do NOT build any other feature routes today.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â”œâ”€â”€ middleware/
â”‚    â”œâ”€â”€ __init__.py
â”‚    â”œâ”€â”€ auth.py
â”‚    â””â”€â”€ rbac.py
â””â”€â”€ admin/
     â””â”€â”€ auth/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 1 â€” middleware/auth.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Verify JWT on every protected route.
  Inject current admin user into Flask g object.
  Block inactive/deactivated admins.

Imports needed:
  from functools import wraps
  from flask import g, request, jsonify
  from flask_jwt_extended import (
    verify_jwt_in_request,
    get_jwt_identity,
    get_jwt
  )
  from models import User

Functions to build:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
require_auth (decorator):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Usage: @require_auth on any route function

  Steps:
  1. Call verify_jwt_in_request()
     Flask-JWT-Extended handles signature/expiry.
     If invalid: JWT callbacks in extensions.py
       return 401 automatically.

  2. Get identity: get_jwt_identity()
     This is the user ID stored in token.

  3. Query user from DB:
     user = User.query.get(identity)
     If not found:
       Return { success: False,
         message: 'Admin account not found',
         code: 'ACCOUNT_NOT_FOUND' } 401

  4. Check user status:
     If user.status != 'active':
       Return { success: False,
         message: 'Account is deactivated.
           Contact system administrator.',
         code: 'ACCOUNT_DEACTIVATED' } 403

  5. Inject into Flask g:
     g.current_admin = user
     g.current_admin_id = str(user.id)
     g.jwt_claims = get_jwt()
       â† store full claims for role checks

  6. Call wrapped function and return result.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
get_current_admin():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Return g.current_admin
  If g does not have current_admin:
    Return None
  Called inside route handlers.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
get_current_admin_id():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Return g.current_admin_id as string
  If not set: return None

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
get_request_ip():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Check X-Forwarded-For header first
    (for reverse proxy / nginx deployments)
  Fallback: request.remote_addr
  Return first IP if comma-separated list

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
get_request_user_agent():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Return request.headers.get('User-Agent', 'Unknown')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 2 â€” middleware/rbac.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Enforce role-based access on routes.
  Works AFTER require_auth (auth runs first).

Role hierarchy (higher = more access):
  SUPER_ADMIN = 4
  MANAGER     = 3
  ANALYST     = 2
  USER        = 1

ROLE_HIERARCHY = {
  'SUPER_ADMIN': 4,
  'MANAGER': 3,
  'ANALYST': 2,
  'USER': 1
}

Functions to build:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
require_role(*allowed_roles) (decorator factory):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Usage:
    @require_auth
    @require_role('SUPER_ADMIN', 'MANAGER')
    def my_route():

  Steps:
  1. Get current admin from g.current_admin
  2. If admin.role not in allowed_roles:
     Return { success: False,
       message: 'You do not have permission
         to perform this action.',
       required_roles: list(allowed_roles),
       your_role: admin.role,
       code: 'INSUFFICIENT_ROLE' } 403
  3. Else: call wrapped function

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
require_min_role(min_role) (decorator factory):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Usage:
    @require_auth
    @require_min_role('MANAGER')
    def my_route():
    â† allows MANAGER and SUPER_ADMIN

  Steps:
  1. Get current admin from g.current_admin
  2. Get role levels:
     admin_level = ROLE_HIERARCHY[admin.role]
     min_level = ROLE_HIERARCHY[min_role]
  3. If admin_level < min_level:
     Return same 403 as require_role
  4. Else: call wrapped function

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
is_super_admin():
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Helper â€” returns Boolean
  Return g.current_admin.role == 'SUPER_ADMIN'
  Used for conditional logic inside routes
  NOT a decorator

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
can_manage_role(target_role):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Returns Boolean
  Current admin can only manage roles
  strictly BELOW their own level.
  SUPER_ADMIN can manage all.
  MANAGER cannot manage MANAGER or SUPER_ADMIN.
  ANALYST cannot manage anyone.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 3 â€” middleware/__init__.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Export all middleware:

from .auth import (
    require_auth,
    get_current_admin,
    get_current_admin_id,
    get_request_ip,
    get_request_user_agent
)
from .rbac import (
    require_role,
    require_min_role,
    is_super_admin,
    can_manage_role,
    ROLE_HIERARCHY
)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 4 â€” admin/auth/routes.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Blueprint setup:
  auth_bp = Blueprint('auth', __name__)

Rate limiting (applied per endpoint):
  Login: 10 per minute per IP
    â† Brute force protection
  Refresh: 30 per minute per IP
  Others: default limiter rules

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENDPOINT 1 â€” POST /api/admin/auth/login
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Rate limit: 10 per minute
  Auth required: NO (public endpoint)

  Request body:
    { email: String, password: String }

  Validation:
    email: required, valid email format
    password: required, min 6 chars
    If missing: return 400 with field errors

  Logic:
  1. Find user by email:
     user = User.query.filter_by(email=email).first()

  2. If not found OR password wrong:
     Return SAME error for both cases:
       { success: False,
         message: 'Invalid email or password',
         code: 'INVALID_CREDENTIALS' } 401
     â† Same message prevents user enumeration

  3. If user.status == 'inactive':
     Return { success: False,
       message: 'Account is deactivated.',
       code: 'ACCOUNT_DEACTIVATED' } 403

  4. If user.role == 'USER':
     Return { success: False,
       message: 'Access denied. Admin accounts only.',
       code: 'NOT_ADMIN' } 403
     â† Regular users cannot access admin panel

  5. Generate tokens:
     access_token = create_access_token(
       identity=str(user.id),
       additional_claims={
         'name': user.name,
         'email': user.email,
         'role': user.role
       }
     )
     refresh_token = create_refresh_token(
       identity=str(user.id)
     )

  6. Update last_active:
     user.last_active = datetime.utcnow()
     db.session.commit()

  7. Log the login action:
     AuditLog.create(
       admin_id=user.id,
       action_type='LOGIN',
       target_table='auth',
       summary=f'{user.name} logged in',
       ip_address=get_request_ip(),
       user_agent=get_request_user_agent()
     )

  8. Return:
     {
       success: True,
       message: 'Login successful',
       data: {
         access_token: String,
         refresh_token: String,
         token_type: 'Bearer',
         expires_in: seconds (from config),
         admin: {
           id, name, email, role,
           risk_level (always low for admins)
         }
       }
     } 200

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENDPOINT 2 â€” POST /api/admin/auth/logout
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Rate limit: default
  Auth required: YES (@require_auth)

  Logic:
  1. Get current admin from g
  2. Log the logout:
     AuditLog.create(
       admin_id=current_admin.id,
       action_type='LOGOUT',
       target_table='auth',
       summary=f'{current_admin.name} logged out',
       ip_address=get_request_ip(),
       user_agent=get_request_user_agent()
     )
  3. Return:
     { success: True,
       message: 'Logged out successfully' } 200

  Note:
  JWT is stateless â€” actual token invalidation
  requires a blocklist (Redis). For now,
  frontend clears the token on logout.
  Add a comment: # TODO: implement token blocklist
    with Redis for production token revocation

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENDPOINT 3 â€” POST /api/admin/auth/refresh
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Rate limit: 30 per minute
  Auth required: YES but with refresh token
    Use: @jwt_required(refresh=True)
    NOT @require_auth (different token type)

  Logic:
  1. Get identity from refresh token:
     identity = get_jwt_identity()

  2. Verify user still exists + active:
     user = User.query.get(identity)
     If not found or inactive: return 401/403

  3. Generate new access token only:
     new_access = create_access_token(
       identity=str(user.id),
       additional_claims={
         'name': user.name,
         'email': user.email,
         'role': user.role
       }
     )

  4. Return:
     {
       success: True,
       message: 'Token refreshed',
       data: {
         access_token: new_access,
         token_type: 'Bearer'
       }
     } 200

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENDPOINT 4 â€” GET /api/admin/auth/me
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Auth required: YES (@require_auth)

  Logic:
  1. Get current admin from g
  2. Return full admin profile
  3. Return:
     {
       success: True,
       data: {
         admin: current_admin.to_dict(),
         permissions: {
           can_manage_foods: role in [SUPER_ADMIN, MANAGER],
           can_manage_orders: role in [SUPER_ADMIN, MANAGER],
           can_manage_users: role in [SUPER_ADMIN, MANAGER],
           can_change_roles: role == SUPER_ADMIN,
           can_retrain_ai: role == SUPER_ADMIN,
           can_view_analytics: True (all admin roles),
           can_export: True (all admin roles)
         }
       }
     } 200

  â† Frontend uses permissions object to control
    UI visibility instead of hard-coding role names

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENDPOINT 5 â€” PUT /api/admin/auth/password
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Auth required: YES (@require_auth)

  Request body:
    {
      current_password: String,
      new_password: String,
      confirm_password: String
    }

  Validation:
    All 3 fields required
    new_password min 8 chars
    new_password must contain:
      At least 1 uppercase letter
      At least 1 lowercase letter
      At least 1 number
      At least 1 special character
    new_password != current_password
    new_password == confirm_password
    If any fail: return 400 with specific error messages

  Logic:
  1. Get current admin
  2. Verify current_password:
     If not admin.check_password(current_password):
       Return { success: False,
         message: 'Current password is incorrect',
         code: 'WRONG_PASSWORD' } 401
  3. Set new password:
     admin.set_password(new_password)
     db.session.commit()
  4. Log action:
     AuditLog.create(
       admin_id=admin.id,
       action_type='UPDATE',
       target_table='auth',
       summary=f'{admin.name} changed their password',
       ip_address=get_request_ip()
     )
  5. Return:
     { success: True,
       message: 'Password updated successfully.
         Please log in again.' } 200

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
UPDATE app.py â€” Register Auth Blueprint:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inside create_app(), in the blueprints section,
uncomment/add:

  from admin.auth.routes import auth_bp
  app.register_blueprint(auth_bp,
    url_prefix='/api/admin/auth')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VALIDATION HELPER â€” utils/validators.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Create this file today as it is needed by auth routes
and will be reused by every other route module:

Functions:

validate_required(data, fields):
  Accepts: dict of request data, list of field names
  Returns: { valid: Boolean, errors: dict }
  Checks each field exists and is not empty string.
  errors format: { field_name: 'Field is required' }

validate_email(email):
  Simple regex check for valid email format.
  Return Boolean.

validate_password_strength(password):
  Check all 4 rules:
    min 8 chars
    has uppercase
    has lowercase
    has digit
    has special char (!@#$%^&*...)
  Return { valid: Boolean, errors: [String] }
  errors: list of specific failing rules

validate_enum(value, allowed_values, field_name):
  Check value is in allowed_values list
  Return { valid: Boolean,
    error: f'{field_name} must be one of: ...' }

sanitize_string(value, max_length=None):
  Strip whitespace
  Truncate to max_length if provided
  Return cleaned string

parse_int(value, default=None, min_val=None):
  Try int(value)
  Apply min_val check if provided
  Return int or default on failure

parse_date(value):
  Try parsing ISO date string (YYYY-MM-DD)
  Return date object or None on failure

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION STEPS â€” README_DAY3.md:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1 â€” Start server:
  python run.py

Step 2 â€” Test login with wrong credentials:
  curl -X POST http://localhost:5000/api/admin/auth/login
    -H "Content-Type: application/json"
    -d '{"email":"wrong@test.com","password":"wrong"}'
  Expected: 401 { code: 'INVALID_CREDENTIALS' }

Step 3 â€” Test login with deactivated account:
  (Manually set a user status to inactive in DB first)
  Expected: 403 { code: 'ACCOUNT_DEACTIVATED' }

Step 4 â€” Test successful login:
  curl -X POST http://localhost:5000/api/admin/auth/login
    -H "Content-Type: application/json"
    -d '{"email":"admin@canteen.com",
         "password":"Admin@123"}'
  Expected: 200 with access_token + refresh_token

Step 5 â€” Copy access_token. Test /me endpoint:
  curl http://localhost:5000/api/admin/auth/me
    -H "Authorization: Bearer {access_token}"
  Expected: 200 with admin profile + permissions

Step 6 â€” Test /me without token:
  curl http://localhost:5000/api/admin/auth/me
  Expected: 401 { code: 'TOKEN_MISSING' }

Step 7 â€” Test /me with fake token:
  curl http://localhost:5000/api/admin/auth/me
    -H "Authorization: Bearer fake.token.here"
  Expected: 401 { code: 'TOKEN_INVALID' }

Step 8 â€” Test token refresh:
  curl -X POST
    http://localhost:5000/api/admin/auth/refresh
    -H "Authorization: Bearer {refresh_token}"
  Expected: 200 with new access_token

Step 9 â€” Test logout:
  curl -X POST
    http://localhost:5000/api/admin/auth/logout
    -H "Authorization: Bearer {access_token}"
  Expected: 200 { message: 'Logged out successfully' }

Step 10 â€” Verify audit log recorded:
  psql canteen_dev -c "
    SELECT action_type, summary, ip_address,
      timestamp FROM admin_audit_logs
    ORDER BY timestamp DESC LIMIT 5;"
  Expected: LOGIN + LOGOUT entries visible

If all 10 pass: Day 3 complete.
Ready for Day 4 â€” Audit middleware.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- Login returns SAME error for wrong email
  AND wrong password â€” never distinguish between them
- USER role accounts blocked from admin panel
  at login â€” not just at route level
- require_auth and require_role are separate decorators
  Always stack: @require_auth first, @require_role second
- Refresh endpoint uses jwt_required(refresh=True)
  NOT require_auth (different token type)
- All audit log writes wrapped in try/except
  Auth must work even if audit log fails
- Password validation runs BEFORE checking
  current password (fail fast on format errors)
- get_request_ip() checks X-Forwarded-For first
  for correct IP behind nginx/reverse proxy
- permissions dict in /me response drives
  frontend UI visibility â€” keep it complete
- validators.py imported by auth routes today
  and reused by all future route modules
- No business logic in middleware files â€”
  middleware only verifies and injects
- All imports from extensions.py not from app.py
  to prevent circular imports
```

---
Here's the complete Day 4 prompt:

---

## ğŸ”· DAY 4 PROMPT â€” RBAC Middleware + Audit Middleware

```
Build the Day 4 middleware layer of a Flask backend
for an AI-Enabled Smart Canteen Admin System.

Days 1, 2, 3 are complete:
  App factory, config, extensions exist.
  All 10 models and migrations done.
  Auth middleware + JWT login/logout endpoints done.
  JWT token generation and verification working.

Day 4 covers ONLY:
  1. RBAC middleware (role enforcement decorator)
  2. Audit middleware (automatic action logging)
  3. Request context utilities
  4. Wiring both middleware into existing auth routes

Do NOT build any page-specific routes today.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ middleware/
     â”œâ”€â”€ __init__.py      â† update
     â”œâ”€â”€ auth.py          â† already exists (Day 3)
     â”œâ”€â”€ rbac.py          â† create today
     â””â”€â”€ audit.py         â† create today

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 1 â€” middleware/rbac.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Role-based access control decorator factory.
  Every protected route declares which roles
  are allowed. All others get 403.

ROLE HIERARCHY:
  SUPER_ADMIN = 4  (highest)
  MANAGER     = 3
  ANALYST     = 2
  USER        = 1  (lowest â€” blocked from all admin routes)

ROLE_HIERARCHY dict:
  {
    'SUPER_ADMIN': 4,
    'MANAGER':     3,
    'ANALYST':     2,
    'USER':        1
  }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DECORATOR 1 â€” require_role()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def require_role(*allowed_roles):
  """
  Decorator factory.
  Accepts one or more role strings.
  Route only accessible if current admin role
  is in the allowed_roles tuple.

  Usage examples:
    @require_role('SUPER_ADMIN')
    @require_role('SUPER_ADMIN', 'MANAGER')
    @require_role('SUPER_ADMIN', 'MANAGER', 'ANALYST')

  Must be used AFTER @jwt_required() decorator:
    @bp.route('/endpoint')
    @jwt_required()
    @require_role('MANAGER')
    def endpoint():
      ...
  """

  Implementation:
    Get current admin from flask.g (set by auth middleware)
    If g.current_admin is None:
      Return 401: { success: False,
        message: 'Authentication required' }
    If g.current_admin.role not in allowed_roles:
      Return 403: {
        success: False,
        message: 'Insufficient permissions',
        required_roles: list(allowed_roles),
        your_role: g.current_admin.role
      }
    If admin status is 'inactive':
      Return 403: {
        success: False,
        message: 'Account is deactivated'
      }
    Call wrapped function

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DECORATOR 2 â€” require_min_role()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def require_min_role(min_role):
  """
  Decorator factory.
  Allows any role with level >= min_role level.
  Cleaner for most routes since you rarely
  need to exclude a middle role.

  Usage examples:
    @require_min_role('ANALYST')
      â† allows ANALYST, MANAGER, SUPER_ADMIN
    @require_min_role('MANAGER')
      â† allows MANAGER, SUPER_ADMIN only
    @require_min_role('SUPER_ADMIN')
      â† allows SUPER_ADMIN only

  Must be used AFTER @jwt_required():
    @bp.route('/endpoint')
    @jwt_required()
    @require_min_role('ANALYST')
    def endpoint():
      ...
  """

  Implementation:
    Get current admin from flask.g
    If g.current_admin is None:
      Return 401 as above
    Get current_level = ROLE_HIERARCHY.get(
      g.current_admin.role, 0)
    Get min_level = ROLE_HIERARCHY.get(min_role, 999)
    If current_level < min_level:
      Return 403: {
        success: False,
        message: f'Requires {min_role} role or higher',
        your_role: g.current_admin.role
      }
    If admin status is 'inactive':
      Return 403: { message: 'Account is deactivated' }
    Call wrapped function

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HELPER â€” get_allowed_roles()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_roles_at_or_above(min_role):
  """
  Returns list of role strings at or above min_role.
  Useful for building dynamic role lists.

  Example:
    get_roles_at_or_above('MANAGER')
    â†’ ['MANAGER', 'SUPER_ADMIN']
  """
  min_level = ROLE_HIERARCHY.get(min_role, 0)
  return [role for role, level
    in ROLE_HIERARCHY.items()
    if level >= min_level]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 2 â€” middleware/audit.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Centralized audit logging utility.
  Called explicitly inside every write route handler.
  Captures admin identity, IP, user agent automatically
  from Flask request context.
  Must NEVER break the main request if it fails.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FUNCTION 1 â€” log_action()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def log_action(
    action_type,
    target_table=None,
    target_id=None,
    summary=None,
    payload=None,
    before=None,
    after=None
  ):
  """
  Main audit logging function.
  Called inside route handlers after
  successful DB operations.

  Automatically captures from Flask context:
    admin_id    â† from g.current_admin.id
    ip_address  â† from request.remote_addr
                   Check X-Forwarded-For header first
                   (for reverse proxy setups)
    user_agent  â† from request.headers.get('User-Agent')
    timestamp   â† auto (model default)

  Parameters:
    action_type  â† required: enum string
    target_table â† optional: table name string
    target_id    â† optional: affected record ID as string
    summary      â† optional: human-readable description
                   If None: auto-generate from params
    payload      â† optional: dict of relevant data
    before       â† optional: dict of state before change
    after        â† optional: dict of state after change
  """

  Implementation steps:

  Step 1 â€” Get admin context safely:
    Try to get admin from g.current_admin
    If not available: admin_id = None
      (system-generated log, no admin)

  Step 2 â€” Get IP address:
    Check request.headers.get('X-Forwarded-For') first
      If present: take first IP in comma-separated list
      Trim whitespace
    Fallback to request.remote_addr
    Fallback to '0.0.0.0' if both None

  Step 3 â€” Auto-generate summary if not provided:
    Call _auto_summary(action_type, target_table,
      target_id, payload)

  Step 4 â€” Serialize payload/before/after safely:
    Payload dicts may contain non-JSON-safe types
    Call _safe_serialize(data) on each
    _safe_serialize converts:
      UUID â†’ str
      datetime â†’ ISO string
      Decimal â†’ float
      Anything else non-serializable â†’ str(value)

  Step 5 â€” Create AuditLog record:
    log = AuditLog(
      admin_id=admin_id,
      action_type=action_type,
      target_table=target_table,
      target_id=str(target_id) if target_id else None,
      summary=summary,
      payload=serialized_payload,
      payload_before=serialized_before,
      payload_after=serialized_after,
      ip_address=ip_address,
      user_agent=user_agent
    )
    db.session.add(log)
    db.session.commit()

  Step 6 â€” Exception handling:
    Wrap ENTIRE function in try/except Exception as e:
      On any error:
        db.session.rollback()
        current_app.logger.error(
          f'[AUDIT] Failed to log action: {e}'
        )
        DO NOT re-raise
        â† audit failure must never break main request

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FUNCTION 2 â€” _auto_summary()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _auto_summary(action_type, target_table,
                  target_id, payload):
  """
  Generates human-readable summary string
  when caller does not provide one.

  Examples:
    CREATE, foods, uuid123
      â†’ "Created new food item (id: uuid123)"
    UPDATE, inventory, uuid456
      â†’ "Updated inventory record (id: uuid456)"
    DELETE, users, uuid789
      â†’ "Deleted user record (id: uuid789)"
    LOGIN, auth, None
      â†’ "Admin login"
    LOGOUT, auth, None
      â†’ "Admin logout"
    EXPORT, sales_report, None
      â†’ "Exported sales_report"
    RETRAIN, ai_model, None
      â†’ "Triggered AI model retraining"
    STATUS_CHANGE, orders, uuid111
      â†’ "Changed order status (id: uuid111)"
  """

  Templates dict:
    'CREATE':       f"Created new {target_table} record
                      (id: {target_id})"
    'UPDATE':       f"Updated {target_table} record
                      (id: {target_id})"
    'DELETE':       f"Deleted {target_table} record
                      (id: {target_id})"
    'LOGIN':        "Admin login"
    'LOGOUT':       "Admin logout"
    'EXPORT':       f"Exported {target_table}"
    'RETRAIN':      "Triggered AI model retraining"
    'STATUS_CHANGE': f"Changed {target_table} status
                      (id: {target_id})"

  Fallback: f"{action_type} on {target_table}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FUNCTION 3 â€” _safe_serialize()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _safe_serialize(data):
  """
  Recursively makes a dict JSON-safe.
  Handles nested dicts and lists.
  Never raises â€” always returns something.
  """

  If data is None: return None
  If data is dict:
    Return { k: _safe_serialize(v)
      for k, v in data.items() }
  If data is list:
    Return [_safe_serialize(i) for i in data]
  If isinstance UUID: return str(data)
  If isinstance datetime: return data.isoformat() + 'Z'
  If isinstance Decimal: return float(data)
  If isinstance (str, int, float, bool): return data
  Fallback: return str(data)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONVENIENCE WRAPPERS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

These are thin wrappers around log_action()
for the most common operations:

def log_create(table, record_id, payload=None):
  log_action('CREATE', table, record_id,
    payload=payload)

def log_update(table, record_id, before, after):
  log_action('UPDATE', table, record_id,
    before=before, after=after)

def log_delete(table, record_id, payload=None):
  log_action('DELETE', table, record_id,
    payload=payload)

def log_login(admin_id=None):
  log_action('LOGIN', 'auth',
    summary='Admin login')

def log_logout():
  log_action('LOGOUT', 'auth',
    summary='Admin logout')

def log_export(report_type, config=None):
  log_action('EXPORT', report_type,
    payload=config)

def log_status_change(table, record_id,
                      old_status, new_status):
  log_action('STATUS_CHANGE', table, record_id,
    summary=f'Status changed from {old_status}
      to {new_status}',
    before={'status': old_status},
    after={'status': new_status})

def log_retrain(accuracy_before=None):
  log_action('RETRAIN', 'ai_model',
    payload={'accuracy_before': accuracy_before})

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 3 â€” middleware/__init__.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Export everything cleanly:

from .auth import require_auth, get_current_admin
from .rbac import (
    require_role,
    require_min_role,
    get_roles_at_or_above,
    ROLE_HIERARCHY
)
from .audit import (
    log_action,
    log_create,
    log_update,
    log_delete,
    log_login,
    log_logout,
    log_export,
    log_status_change,
    log_retrain
)

__all__ = [
    'require_auth', 'get_current_admin',
    'require_role', 'require_min_role',
    'get_roles_at_or_above', 'ROLE_HIERARCHY',
    'log_action', 'log_create', 'log_update',
    'log_delete', 'log_login', 'log_logout',
    'log_export', 'log_status_change', 'log_retrain'
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
UPDATE â€” admin/auth/routes.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Go back to Day 3 auth routes and wire in
audit logging now that audit.py exists.

Update POST /api/admin/auth/login:
  After successful login:
    Add: log_login()
    â† logs the login action with admin IP

Update POST /api/admin/auth/logout:
  Before clearing token:
    Add: log_logout()
    â† logs the logout action

These are the only 2 changes to existing files.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USAGE PATTERN â€” HOW TO USE IN ROUTES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Document this pattern clearly so all
future route files follow it consistently.

EXAMPLE ROUTE using all 3 middleware:

  from middleware import (
      require_min_role,
      log_update
  )
  from flask_jwt_extended import jwt_required

  @bp.route('/foods/<uuid:food_id>', methods=['PUT'])
  @jwt_required()
  @require_min_role('MANAGER')
  def update_food(food_id):
    # 1. Get current state BEFORE update
    food = FoodItem.query.get_or_404(food_id)
    before_state = food.to_dict()

    # 2. Apply changes
    data = request.get_json()
    food.name = data.get('name', food.name)
    db.session.commit()

    # 3. Log AFTER successful commit
    log_update('food_items', food_id,
      before=before_state,
      after=food.to_dict())

    return success(food.to_dict(), 'Food updated')

RULES illustrated by example:
  â† @jwt_required() always first
  â† @require_min_role() always second
  â† Capture before_state BEFORE any changes
  â† log_*() called AFTER successful db.commit()
  â† Never log if commit fails (no misleading audit)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION STEPS â€” README_DAY4.md:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1 â€” Test RBAC blocks low role:
  Login as ANALYST:
    POST /api/admin/auth/login
    { email, password }
    Save token as ANALYST_TOKEN

  Try to access MANAGER-only endpoint:
    PUT /api/admin/foods/{any_id}
    Header: Authorization: Bearer ANALYST_TOKEN
    Expected: 403 {
      message: 'Insufficient permissions',
      required_roles: ['MANAGER', 'SUPER_ADMIN'],
      your_role: 'ANALYST'
    }

Step 2 â€” Test RBAC allows correct role:
  Login as SUPER_ADMIN:
    Save token as ADMIN_TOKEN

  Try same endpoint:
    PUT /api/admin/foods/{any_id}
    Header: Authorization: Bearer ADMIN_TOKEN
    Expected: NOT 403
      (may get 404 if food doesn't exist â€” that's fine)

Step 3 â€” Test audit logging on login:
  Login:
    POST /api/admin/auth/login
  Check audit table:
    psql canteen_dev -c "
      SELECT action_type, summary, ip_address,
        timestamp FROM admin_audit_logs
      ORDER BY timestamp DESC LIMIT 3;"
  Expected: Row with action_type='LOGIN'
    ip_address='127.0.0.1'

Step 4 â€” Test audit logging on logout:
  POST /api/admin/auth/logout
    Header: Authorization: Bearer TOKEN
  Check audit table again.
  Expected: Row with action_type='LOGOUT'

Step 5 â€” Test deactivated admin blocked:
  Manually deactivate seed admin in DB:
    psql canteen_dev -c "
      UPDATE users SET status='inactive'
      WHERE email='admin@canteen.com';"
  Try any protected endpoint with their token:
  Expected: 403 { message: 'Account is deactivated' }
  Re-activate after test:
    UPDATE users SET status='active' ...

Step 6 â€” Test audit failure safety:
  Temporarily break DB connection mid-request
  OR mock AuditLog to raise an exception
  Verify: Main request still returns 200
  Verify: Error logged to app.logger
  Verify: No 500 error surfaced to client

Step 7 â€” Test X-Forwarded-For IP capture:
  Send request with header:
    X-Forwarded-For: 203.0.113.42
  Check audit log:
    ip_address should be '203.0.113.42'
    not '127.0.0.1'

If all 7 pass: Day 4 complete.
Ready for Day 5 utils.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- Both decorators MUST be used after @jwt_required()
  Never before â€” order is: jwt â†’ rbac â†’ handler
- require_role() for exact role matching
  require_min_role() for hierarchy-based matching
  Use require_min_role() for most routes
  Use require_role() only when excluding a middle role
- log_action() wraps entire body in try/except
  It must NEVER raise under any circumstance
- before= state captured BEFORE db.commit()
  after= state captured AFTER db.commit()
  This is non-negotiable â€” wrong order = wrong audit
- _safe_serialize() handles ALL types recursively
  No audit log entry should ever fail due to
  non-serializable data types
- Convenience wrappers (log_create, log_update etc.)
  preferred over raw log_action() in route handlers
  Keeps route handlers clean and readable
- IP from X-Forwarded-For takes priority over
  remote_addr for reverse proxy compatibility
- No imports from app.py in middleware files
  Use current_app for app context access
- No circular imports:
  middleware imports from models and extensions only
  Never from admin/ route files
```

---

Here's the complete Day 5 prompt:

---

## ğŸ”· DAY 5 PROMPT â€” Response Utils + Pagination + Validators + Formatters

```
Build the Day 5 utilities layer of a Flask backend
for an AI-Enabled Smart Canteen Admin System.

Days 1â€“4 are complete:
  App factory, config, extensions exist.
  All 10 models and migrations done.
  Auth middleware + JWT login/logout working.
  RBAC middleware + audit middleware done.

Day 5 covers ONLY:
  1. Standardized response utility (response.py)
  2. Reusable pagination utility (pagination.py)
  3. Input validation utility (validators.py)
  4. Date/number formatting helpers (formatters.py)

Do NOT build any page-specific routes today.
These utils are the last shared layer before
Week 2 route building begins.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ utils/
     â”œâ”€â”€ __init__.py
     â”œâ”€â”€ response.py
     â”œâ”€â”€ pagination.py
     â”œâ”€â”€ validators.py
     â””â”€â”€ formatters.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 1 â€” utils/response.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Single source of truth for all API responses.
  Every route handler returns via these functions.
  Guarantees consistent response shape across
  all 9 pages and 40+ endpoints.

STANDARD RESPONSE SHAPE:
  Success:
  {
    "success": true,
    "message": "string",
    "data": { ... } or [ ... ] or null
  }

  Error:
  {
    "success": false,
    "message": "string",
    "errors": [ ... ] or []
  }

  Paginated:
  {
    "success": true,
    "message": "string",
    "data": [ ... ],
    "pagination": {
      "total": Number,
      "page": Number,
      "pages": Number,
      "per_page": Number,
      "has_next": Boolean,
      "has_prev": Boolean
    }
  }

FUNCTIONS TO BUILD:

def success(data=None, message='Success', status=200):
  """
  Standard success response.
  Usage:
    return success(food.to_dict(), 'Food created', 201)
    return success(foods_list, 'Foods retrieved')
    return success(message='Deleted successfully')
  """
  return jsonify({
    'success': True,
    'message': message,
    'data': data
  }), status

def error(message='An error occurred',
          status=400,
          errors=None):
  """
  Standard error response.
  Usage:
    return error('Food not found', 404)
    return error('Validation failed', 422,
      errors=['Name is required', 'Calories must be > 0'])
  """
  return jsonify({
    'success': False,
    'message': message,
    'errors': errors or []
  }), status

def paginated(data, pagination_obj, message='Success'):
  """
  Paginated list response.
  Accepts data list + pagination metadata dict.
  Usage:
    return paginated(
      [item.to_dict() for item in items],
      pagination_meta,
      'Logs retrieved'
    )
  """
  return jsonify({
    'success': True,
    'message': message,
    'data': data,
    'pagination': pagination_obj
  }), 200

def created(data=None, message='Created successfully'):
  """
  Shorthand for 201 Created.
  Usage:
    return created(food.to_dict(), 'Food item created')
  """
  return success(data, message, 201)

def no_content(message='Deleted successfully'):
  """
  Shorthand for successful delete with no body data.
  Returns 200 with null data (not 204 â€” keeps
  consistent JSON body for frontend error handling).
  Usage:
    return no_content('Food item deleted')
  """
  return success(None, message, 200)

def forbidden(message='Insufficient permissions'):
  """
  Shorthand for 403.
  """
  return error(message, 403)

def not_found(resource='Resource'):
  """
  Shorthand for 404.
  Usage:
    return not_found('Food item')
    â†’ { message: 'Food item not found' }
  """
  return error(f'{resource} not found', 404)

def conflict(message='Resource already exists'):
  """
  Shorthand for 409.
  Usage:
    return conflict('Order already completed')
  """
  return error(message, 409)

def unprocessable(message='Cannot process request',
                  errors=None):
  """
  Shorthand for 422 â€” business logic rejection.
  Usage:
    return unprocessable(
      'Cannot delete food with active orders'
    )
  """
  return error(message, 422, errors)

def server_error(message='Internal server error'):
  """
  Shorthand for 500.
  Never expose internal details.
  """
  return error(message, 500)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 2 â€” utils/pagination.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Reusable pagination for any SQLAlchemy query.
  Used by orders, audit logs, AI logs, users.
  Parses page/limit from request args safely.
  Returns both paginated data and metadata.

CONSTANTS:
  DEFAULT_PAGE     = 1
  DEFAULT_PER_PAGE = 20
  MAX_PER_PAGE     = 100
  MIN_PER_PAGE     = 5

FUNCTION 1 â€” paginate_query()

def paginate_query(query, page=None,
                   per_page=None,
                   max_per_page=MAX_PER_PAGE):
  """
  Paginates any SQLAlchemy query object.

  Parameters:
    query      â† SQLAlchemy query (not yet executed)
    page       â† page number (1-indexed)
    per_page   â† items per page
    max_per_page â† hard ceiling on per_page

  Returns: tuple (items, pagination_meta)
    items         â† list of model objects
    pagination_meta â† dict with pagination info

  Usage:
    query = Order.query.filter_by(status='pending')
    items, meta = paginate_query(query, page=2,
      per_page=20)
    return paginated(
      [i.to_dict() for i in items], meta
    )
  """

  Implementation:
    Clamp page: max(1, int(page or DEFAULT_PAGE))
    Clamp per_page:
      requested = int(per_page or DEFAULT_PER_PAGE)
      per_page = min(max(MIN_PER_PAGE, requested),
        max_per_page)

    Execute paginated query:
      pagination = query.paginate(
        page=page,
        per_page=per_page,
        error_out=False
      )

    Build metadata dict:
      {
        'total':    pagination.total,
        'page':     pagination.page,
        'pages':    pagination.pages,
        'per_page': pagination.per_page,
        'has_next': pagination.has_next,
        'has_prev': pagination.has_prev,
        'next_page': pagination.next_num
          if pagination.has_next else None,
        'prev_page': pagination.prev_num
          if pagination.has_prev else None
      }

    Return (pagination.items, metadata)

FUNCTION 2 â€” get_pagination_args()

def get_pagination_args():
  """
  Safely extracts and validates pagination args
  from Flask request.args.

  Returns: (page, per_page) tuple of safe integers.

  Usage at top of route handler:
    page, per_page = get_pagination_args()
    items, meta = paginate_query(query,
      page, per_page)
  """

  Implementation:
    page = request.args.get('page', DEFAULT_PAGE)
    per_page = request.args.get(
      'per_page', DEFAULT_PER_PAGE)

    Try to convert both to int
    On ValueError: use defaults

    Clamp both to safe ranges:
      page = max(1, page)
      per_page = min(
        max(MIN_PER_PAGE, per_page),
        MAX_PER_PAGE
      )

    Return (page, per_page)

FUNCTION 3 â€” paginate_list()

def paginate_list(items_list, page, per_page):
  """
  Paginates a Python list (not a DB query).
  Used when data is already in memory
  (e.g. after heavy in-memory processing).

  Returns: (paginated_items, pagination_meta)
  """

  total = len(items_list)
  pages = max(1, -(-total // per_page))
    â† ceiling division

  start = (page - 1) * per_page
  end   = start + per_page
  items = items_list[start:end]

  meta = {
    'total':     total,
    'page':      page,
    'pages':     pages,
    'per_page':  per_page,
    'has_next':  page < pages,
    'has_prev':  page > 1,
    'next_page': page + 1 if page < pages else None,
    'prev_page': page - 1 if page > 1 else None
  }

  return (items, meta)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 3 â€” utils/validators.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Input validation for all route request bodies.
  Called at the top of every write route handler.
  Returns structured errors, never raises.
  Keeps route handlers clean â€” no inline validation.

VALIDATOR CLASS:

class RequestValidator:
  """
  Chainable validator for request body dicts.

  Usage:
    validator = RequestValidator(request.get_json())
    validator \
      .required('name', 'category', 'calories') \
      .string('name', min_len=2, max_len=100) \
      .number('calories', min_val=0) \
      .number('sugar', min_val=0) \
      .enum('category', ['Meals','Snacks',
        'Beverages','Desserts','Healthy']) \
      .url('image_url', required=False)

    if not validator.is_valid():
      return error('Validation failed', 422,
        errors=validator.get_errors())

    data = validator.get_data()
  """

  def __init__(self, data):
    self._data   = data or {}
    self._errors = []
    self._valid  = True

  METHODS:

  def required(*field_names):
    """
    Check all listed fields exist and are not
    None, empty string, or missing from dict.
    Adds error per missing field.
    Returns self for chaining.
    """

  def string(field, min_len=None,
             max_len=None, required=True):
    """
    Validate field is a string.
    Optionally check min/max length.
    If not required and field absent: skip.
    Errors:
      '[field] must be a string'
      '[field] must be at least {min} characters'
      '[field] must be at most {max} characters'
    Returns self.
    """

  def number(field, min_val=None,
             max_val=None, integer=False,
             required=True):
    """
    Validate field is numeric.
    Try float() conversion.
    If integer=True: must be whole number.
    Errors:
      '[field] must be a number'
      '[field] must be at least {min}'
      '[field] must be at most {max}'
      '[field] must be a whole number'
    Returns self.
    """

  def enum(field, allowed_values, required=True):
    """
    Validate field value is in allowed list.
    Case-sensitive comparison.
    Error:
      '[field] must be one of: Meals, Snacks, ...'
    Returns self.
    """

  def boolean(field, required=True):
    """
    Validate field is a boolean.
    Also accepts 0/1 as boolean equivalents.
    Error:
      '[field] must be true or false'
    Returns self.
    """

  def url(field, required=False):
    """
    Validate field is a valid URL if present.
    Must start with http:// or https://
    If required=False and field absent: skip.
    Error:
      '[field] must be a valid URL
        starting with http:// or https://'
    Returns self.
    """

  def uuid_field(field, required=True):
    """
    Validate field is a valid UUID string.
    Try uuid.UUID(value) conversion.
    Error:
      '[field] must be a valid UUID'
    Returns self.
    """

  def date_string(field, required=True):
    """
    Validate field is ISO date string YYYY-MM-DD.
    Try datetime.strptime(value, '%Y-%m-%d').
    Error:
      '[field] must be a valid date
        in format YYYY-MM-DD'
    Returns self.
    """

  def is_valid():
    """ Return True if no errors collected. """
    return len(self._errors) == 0

  def get_errors():
    """ Return list of error strings. """
    return self._errors

  def get_data():
    """
    Return the original data dict.
    Only call after is_valid() returns True.
    """
    return self._data

  def get(field, default=None):
    """
    Safely get a value from validated data.
    Shorthand for self._data.get(field, default)
    """
    return self._data.get(field, default)

STANDALONE VALIDATORS
(for use outside the class):

def validate_uuid(value):
  """
  Returns True if value is valid UUID string.
  """
  try:
    uuid.UUID(str(value))
    return True
  except (ValueError, AttributeError):
    return False

def validate_date(value):
  """
  Returns True if value is valid YYYY-MM-DD string.
  """
  try:
    datetime.strptime(value, '%Y-%m-%d')
    return True
  except (ValueError, TypeError):
    return False

def validate_date_range(from_date, to_date):
  """
  Validates both dates are valid AND from <= to.
  Returns (True, None) or (False, error_message).
  """
  if not validate_date(from_date):
    return False, 'from date is invalid (use YYYY-MM-DD)'
  if not validate_date(to_date):
    return False, 'to date is invalid (use YYYY-MM-DD)'
  from_dt = datetime.strptime(from_date, '%Y-%m-%d')
  to_dt   = datetime.strptime(to_date,   '%Y-%m-%d')
  if from_dt > to_dt:
    return False, 'from date must be before to date'
  return True, None

def sanitize_string(value, max_length=None):
  """
  Strip whitespace, optionally truncate.
  Returns cleaned string or None if input is None.
  """
  if value is None: return None
  cleaned = str(value).strip()
  if max_length: cleaned = cleaned[:max_length]
  return cleaned if cleaned else None

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 4 â€” utils/formatters.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Purpose:
  Date, time, number, and string formatting helpers.
  Used across all route handlers and model methods.
  Ensures consistent formatting in all API responses.

DATETIME FORMATTERS:

def to_iso(dt):
  """
  Convert datetime to ISO 8601 string with Z suffix.
  Returns None if dt is None.
  Usage: to_iso(order.created_at)
    â†’ '2025-02-21T14:32:07Z'
  """
  if dt is None: return None
  return dt.strftime('%Y-%m-%dT%H:%M:%SZ')

def to_display_date(dt):
  """
  Human-readable date.
  Usage: to_display_date(order.created_at)
    â†’ '21 Feb 2025'
  """
  if dt is None: return None
  return dt.strftime('%-d %b %Y')

def to_display_datetime(dt):
  """
  Human-readable date + time.
  Usage: to_display_datetime(order.created_at)
    â†’ '21 Feb 2025, 2:45 PM'
  """
  if dt is None: return None
  return dt.strftime('%-d %b %Y, %-I:%M %p')

def to_relative_time(dt):
  """
  Human-readable relative time from now.
  Returns:
    'Just now'          â† < 60 seconds
    '5 minutes ago'     â† < 60 minutes
    '2 hours ago'       â† < 24 hours
    'Yesterday'         â† < 48 hours
    '3 days ago'        â† < 7 days
    '2 weeks ago'       â† < 30 days
    '3 months ago'      â† < 365 days
    '2 years ago'       â† >= 365 days
    'Never'             â† if dt is None
  """
  if dt is None: return 'Never'

  now   = datetime.utcnow()
  delta = now - dt
  secs  = int(delta.total_seconds())

  if secs < 60:      return 'Just now'
  if secs < 3600:    return f'{secs // 60} minutes ago'
  if secs < 86400:   return f'{secs // 3600} hours ago'
  if secs < 172800:  return 'Yesterday'
  if secs < 604800:  return f'{secs // 86400} days ago'
  if secs < 2592000: return f'{secs // 604800} weeks ago'
  if secs < 31536000:
    return f'{secs // 2592000} months ago'
  return f'{secs // 31536000} years ago'

def parse_date_arg(date_str, default=None):
  """
  Safely parse YYYY-MM-DD query param to datetime.
  Returns datetime object or default if invalid.
  Usage:
    from_dt = parse_date_arg(
      request.args.get('from'))
  """
  if not date_str: return default
  try:
    return datetime.strptime(date_str, '%Y-%m-%d')
  except (ValueError, TypeError):
    return default

def get_date_range_or_default(from_str, to_str,
                               default_days=30):
  """
  Parse from/to date strings.
  If both absent: default to last {default_days} days.
  If only one present: use it as anchor.
  Returns (from_dt, to_dt) tuple of datetime objects.

  Usage:
    from_dt, to_dt = get_date_range_or_default(
      request.args.get('from'),
      request.args.get('to'),
      default_days=30
    )
  """
  to_dt   = parse_date_arg(to_str) or datetime.utcnow()
  from_dt = parse_date_arg(from_str) or (
    to_dt - timedelta(days=default_days)
  )
  return (from_dt, to_dt)

NUMBER FORMATTERS:

def format_currency(amount, symbol='â‚¹'):
  """
  Format number as currency string.
  Usage: format_currency(45230.5)
    â†’ 'â‚¹45,230.50'
  """
  if amount is None: return f'{symbol}0.00'
  return f'{symbol}{amount:,.2f}'

def format_percentage(value, decimals=1):
  """
  Format as percentage string.
  Usage: format_percentage(94.234)
    â†’ '94.2%'
  """
  if value is None: return '0%'
  return f'{round(float(value), decimals)}%'

def format_large_number(value):
  """
  Format large numbers with K/M suffix.
  Usage:
    format_large_number(1500)    â†’ '1.5K'
    format_large_number(2300000) â†’ '2.3M'
    format_large_number(450)     â†’ '450'
  """
  if value is None: return '0'
  value = int(value)
  if value >= 1_000_000:
    return f'{value / 1_000_000:.1f}M'
  if value >= 1_000:
    return f'{value / 1_000:.1f}K'
  return str(value)

def round_decimal(value, places=2):
  """
  Safely round Decimal/float to N places.
  Returns float. Returns 0.0 if None.
  """
  if value is None: return 0.0
  return round(float(value), places)

STRING FORMATTERS:

def format_order_number(number):
  """
  Format integer as order number string.
  Usage: format_order_number(42)
    â†’ 'ORD-00042'
  """
  return f'ORD-{int(number):05d}'

def truncate(text, max_length=40, suffix='...'):
  """
  Truncate string to max_length with suffix.
  Usage: truncate('Long food description...', 20)
    â†’ 'Long food descripti...'
  """
  if not text: return ''
  if len(text) <= max_length: return text
  return text[:max_length - len(suffix)] + suffix

def format_duration(seconds):
  """
  Convert seconds to human readable duration.
  Usage:
    format_duration(90)   â†’ '1m 30s'
    format_duration(3661) â†’ '1h 1m 1s'
    format_duration(None) â†’ 'N/A'
  """
  if seconds is None: return 'N/A'
  seconds = int(seconds)
  hours   = seconds // 3600
  minutes = (seconds % 3600) // 60
  secs    = seconds % 60
  parts   = []
  if hours:   parts.append(f'{hours}h')
  if minutes: parts.append(f'{minutes}m')
  if secs:    parts.append(f'{secs}s')
  return ' '.join(parts) if parts else '0s'

CHANGE CALCULATION:

def calculate_change(current, previous):
  """
  Calculate percentage change between two values.
  Returns dict used by KPI cards.
  Usage:
    calculate_change(12000, 10000)
    â†’ { value: 20.0, direction: 'up',
        formatted: '+20.0%' }

    calculate_change(8000, 10000)
    â†’ { value: 20.0, direction: 'down',
        formatted: '-20.0%' }

    calculate_change(10000, 0)
    â†’ { value: 100.0, direction: 'up',
        formatted: '+100.0%' }
  """
  if not previous or previous == 0:
    if current > 0:
      return {
        'value': 100.0,
        'direction': 'up',
        'formatted': '+100.0%'
      }
    return {
      'value': 0.0,
      'direction': 'neutral',
      'formatted': '0.0%'
    }

  change = ((current - previous) / previous) * 100
  direction = 'up' if change >= 0 else 'down'
  sign = '+' if change >= 0 else ''

  return {
    'value':     round(abs(change), 1),
    'direction': direction,
    'formatted': f'{sign}{round(change, 1)}%'
  }

def get_period_dates(period_str):
  """
  Convert period string to (from_dt, to_dt).
  Used by sales chart period switcher.
  Values: '7d' | '30d' | '90d'
  Returns tuple of datetime objects.
  """
  to_dt = datetime.utcnow()
  days_map = { '7d': 7, '30d': 30, '90d': 90 }
  days = days_map.get(period_str, 30)
  from_dt = to_dt - timedelta(days=days)
  return (from_dt, to_dt)

def get_previous_period(from_dt, to_dt):
  """
  Calculate equivalent previous period for
  comparison (used by KPI change badges).
  Returns (prev_from, prev_to) tuple.

  Example:
    Current:  Jan 22 â†’ Feb 21 (30 days)
    Previous: Dec 23 â†’ Jan 22 (30 days before)
  """
  duration = to_dt - from_dt
  prev_to   = from_dt
  prev_from = from_dt - duration
  return (prev_from, prev_to)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FILE 5 â€” utils/__init__.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Export everything for clean imports:

from .response import (
    success, error, paginated, created,
    no_content, forbidden, not_found,
    conflict, unprocessable, server_error
)
from .pagination import (
    paginate_query, get_pagination_args,
    paginate_list,
    DEFAULT_PAGE, DEFAULT_PER_PAGE, MAX_PER_PAGE
)
from .validators import (
    RequestValidator,
    validate_uuid, validate_date,
    validate_date_range, sanitize_string
)
from .formatters import (
    to_iso, to_display_date, to_display_datetime,
    to_relative_time, parse_date_arg,
    get_date_range_or_default,
    format_currency, format_percentage,
    format_large_number, round_decimal,
    format_order_number, truncate,
    format_duration, calculate_change,
    get_period_dates, get_previous_period
)

__all__ = [
    'success', 'error', 'paginated', 'created',
    'no_content', 'forbidden', 'not_found',
    'conflict', 'unprocessable', 'server_error',
    'paginate_query', 'get_pagination_args',
    'paginate_list',
    'RequestValidator', 'validate_uuid',
    'validate_date', 'validate_date_range',
    'sanitize_string',
    'to_iso', 'to_display_date',
    'to_display_datetime', 'to_relative_time',
    'parse_date_arg', 'get_date_range_or_default',
    'format_currency', 'format_percentage',
    'format_large_number', 'round_decimal',
    'format_order_number', 'truncate',
    'format_duration', 'calculate_change',
    'get_period_dates', 'get_previous_period'
]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION â€” README_DAY5.md:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Run these in flask shell to verify all utils:

Step 1 â€” Test response utils:
  >>> from utils import success, error, not_found
  >>> success({'id': '123'}, 'Test', 200)
  â† Should return tuple (Response, 200)
  >>> not_found('Food item')
  â† { message: 'Food item not found' } 404

Step 2 â€” Test pagination:
  >>> from utils import paginate_list
  >>> items = list(range(1, 101))
  >>> data, meta = paginate_list(items, 2, 20)
  >>> data
  â† [21, 22, 23, ... 40]
  >>> meta
  â† { total: 100, page: 2, pages: 5,
      has_next: True, has_prev: True }

Step 3 â€” Test validator chaining:
  >>> from utils import RequestValidator
  >>> v = RequestValidator({
  ...   'name': 'Chicken Rice',
  ...   'calories': 450,
  ...   'category': 'Meals'
  ... })
  >>> v.required('name','calories','category') \
  ...  .string('name', min_len=2, max_len=100) \
  ...  .number('calories', min_val=0) \
  ...  .enum('category', ['Meals','Snacks'])
  >>> v.is_valid()
  â† True
  >>> v.get_errors()
  â† []

Step 4 â€” Test validator catches errors:
  >>> v2 = RequestValidator({
  ...   'name': 'X',
  ...   'calories': -5
  ... })
  >>> v2.required('name','calories','category') \
  ...   .string('name', min_len=2) \
  ...   .number('calories', min_val=0) \
  ...   .enum('category', ['Meals'])
  >>> v2.is_valid()
  â† False
  >>> v2.get_errors()
  â† ['name must be at least 2 characters',
      'calories must be at least 0',
      'category is required']

Step 5 â€” Test formatters:
  >>> from utils import to_relative_time
  >>> from datetime import datetime, timedelta
  >>> to_relative_time(
  ...   datetime.utcnow() - timedelta(hours=3))
  â† '3 hours ago'
  >>> to_relative_time(None)
  â† 'Never'

Step 6 â€” Test calculate_change:
  >>> from utils import calculate_change
  >>> calculate_change(12000, 10000)
  â† { value: 20.0, direction: 'up',
      formatted: '+20.0%' }
  >>> calculate_change(8000, 10000)
  â† { value: 20.0, direction: 'down',
      formatted: '-20.0%' }

Step 7 â€” Test date range:
  >>> from utils import get_date_range_or_default
  >>> from_dt, to_dt = get_date_range_or_default(
  ...   None, None, default_days=30)
  >>> (to_dt - from_dt).days
  â† 30

If all 7 pass: Day 5 complete.
Week 1 foundation is fully done.
Ready for Week 2 Day 1 â€” Dashboard routes.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- Every route handler in Week 2+ uses ONLY
  functions from utils/ â€” never raw jsonify()
- RequestValidator is always chainable â€”
  every method returns self
- Validator never raises â€” only collects errors
- All formatter functions handle None input
  gracefully â€” never raise AttributeError
- to_relative_time() uses UTC consistently â€”
  never mix timezone-aware and naive datetimes
- calculate_change() handles division by zero
  (previous = 0) gracefully
- paginate_query() uses SQLAlchemy .paginate()
  with error_out=False so out-of-range pages
  return empty list rather than 404
- paginate_list() uses ceiling division for
  pages calculation â€” never math.ceil import
  needed (use -(-total // per_page) trick)
- get_date_range_or_default() always returns
  datetime objects never strings
- No business logic in utils/ files â€”
  pure functions only, no DB queries
- All utils importable from utils directly:
  from utils import success, paginate_query
  Never: from utils.response import success
```

---

### What Week 1 gives you in full after Day 5:

The entire shared foundation is now done. Every route in Week 2 writes like this:

```python
@bp.route('/foods', methods=['POST'])
@jwt_required()
@require_min_role('MANAGER')
def create_food():
    v = RequestValidator(request.get_json())
    v.required('name','category','calories') \
     .string('name', min_len=2, max_len=100) \
     .number('calories', min_val=0) \
     .enum('category', FOOD_CATEGORIES)
    if not v.is_valid():
        return error('Validation failed', 422,
            errors=v.get_errors())
    # ... db logic ...
    log_create('food_items', food.id, food.to_dict())
    return created(food.to_dict(), 'Food created')
```
Here are all 5 days of Week 2 in one place:

---

## ğŸ”· WEEK 2 DAY 1 â€” Dashboard Routes

```
Build Week 2 Day 1 dashboard routes for the
Flask Admin Backend of Smart Canteen System.

Week 1 is fully complete:
  App factory, config, extensions done.
  All 10 models + migrations done.
  Auth + RBAC + Audit middleware done.
  All utils: response, pagination,
    validators, formatters done.

Day 1 of Week 2 covers ONLY:
  GET /api/admin/overview
  GET /api/admin/analytics/orders-by-hour-today
  GET /api/admin/analytics/sales
  GET /api/admin/analytics/top-items
  GET /api/admin/alerts

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE TO CREATE TODAY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ dashboard/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register blueprint in app.py:
  from admin.dashboard.routes import dashboard_bp
  app.register_blueprint(dashboard_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BLUEPRINT SETUP:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

dashboard_bp = Blueprint('dashboard', __name__)

All imports at top of routes.py:
  from flask import Blueprint, request
  from flask_jwt_extended import jwt_required
  from datetime import datetime, timedelta
  from sqlalchemy import func, extract, text
  from extensions import db
  from models import (Order, OrderItem, FoodItem,
    User, Inventory, AiModelStatus)
  from middleware import require_min_role
  from utils import (success, error,
    to_relative_time, calculate_change,
    get_date_range_or_default, round_decimal,
    format_currency)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/overview
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic â€” Revenue:
  today_start = datetime.utcnow().replace(
    hour=0, minute=0, second=0, microsecond=0)
  last_week_start = today_start - timedelta(days=7)
  last_week_end   = today_start - timedelta(days=1)

  current_revenue = db.session.query(
    func.coalesce(func.sum(Order.total), 0)
  ).filter(
    Order.created_at >= today_start,
    Order.status != 'cancelled'
  ).scalar()

  previous_revenue = db.session.query(
    func.coalesce(func.sum(Order.total), 0)
  ).filter(
    Order.created_at.between(
      last_week_start, last_week_end),
    Order.status != 'cancelled'
  ).scalar()

  revenue_change = calculate_change(
    float(current_revenue),
    float(previous_revenue)
  )

Logic â€” Orders:
  today_orders = Order.query.filter(
    Order.created_at >= today_start
  ).count()

  pending_orders = Order.query.filter(
    Order.created_at >= today_start,
    Order.status == 'pending'
  ).count()

Logic â€” Users:
  active_users = User.query.filter_by(
    status='active', role='USER'
  ).count()

  month_start = datetime.utcnow().replace(
    day=1, hour=0, minute=0, second=0)
  new_this_month = User.query.filter(
    User.joined_at >= month_start,
    User.role == 'USER'
  ).count()

Logic â€” Low Stock:
  low_stock_count = db.session.query(
    func.count(Inventory.id)
  ).filter(
    Inventory.current_stock < Inventory.reorder_level
  ).scalar()

Response:
  return success({
    'revenue': {
      'value':  round_decimal(current_revenue),
      'change': revenue_change['formatted']
    },
    'orders': {
      'value':   today_orders,
      'pending': pending_orders
    },
    'users': {
      'value':        active_users,
      'newThisMonth': new_this_month
    },
    'lowStock': {
      'value': low_stock_count
    }
  }, 'Overview retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” GET /api/admin/analytics/orders-by-hour-today
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  today_start = datetime.utcnow().replace(
    hour=0, minute=0, second=0, microsecond=0)
  current_hour = datetime.utcnow().hour

  canteen_open_hour = 8

  Query orders grouped by hour:
    results = db.session.query(
      extract('hour', Order.created_at)
        .label('hour'),
      func.count(Order.id).label('count')
    ).filter(
      Order.created_at >= today_start,
      extract('hour', Order.created_at)
        >= canteen_open_hour,
      extract('hour', Order.created_at)
        <= current_hour
    ).group_by(
      extract('hour', Order.created_at)
    ).order_by('hour').all()

  Build hour map from canteen_open to current_hour:
    hour_map = {
      h: 0 for h in range(
        canteen_open_hour, current_hour + 1)
    }
    for row in results:
      hour_map[int(row.hour)] = row.count

  Format hours as 12hr strings:
    def format_hour(h):
      if h == 0:   return '12AM'
      if h < 12:   return f'{h}AM'
      if h == 12:  return '12PM'
      return f'{h-12}PM'

    hours  = [format_hour(h)
      for h in sorted(hour_map.keys())]
    counts = [hour_map[h]
      for h in sorted(hour_map.keys())]

Response:
  return success({
    'hours':  hours,
    'counts': counts
  }, 'Hourly data retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” GET /api/admin/analytics/sales
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Query params:
  period = request.args.get('period', '7d')
  Allowed: '7d', '30d', '90d'
  If invalid: default to '7d'

Logic:
  from utils import get_period_dates
  from_dt, to_dt = get_period_dates(period)

  results = db.session.query(
    func.date(Order.created_at).label('date'),
    func.coalesce(
      func.sum(Order.total), 0).label('revenue'),
    func.count(Order.id).label('orders')
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled'
  ).group_by(
    func.date(Order.created_at)
  ).order_by('date').all()

  Build complete date range with 0s for missing days:
    date_map = {}
    current = from_dt.date()
    end     = to_dt.date()
    while current <= end:
      date_map[current] = {'revenue': 0, 'orders': 0}
      current += timedelta(days=1)

    for row in results:
      date_map[row.date] = {
        'revenue': float(row.revenue),
        'orders':  row.orders
      }

  Format labels based on period:
    '7d'  â†’ 'Mon', 'Tue', ...
    '30d' â†’ 'Jan 21', 'Jan 22', ...
    '90d' â†’ 'Week 1', 'Week 2', ... (weekly grouping)

    For '90d': aggregate by week before formatting

  Build parallel arrays:
    labels  = [formatted label per date/week]
    revenue = [values]
    orders  = [values]

Response:
  return success({
    'labels':  labels,
    'revenue': revenue,
    'orders':  orders
  }, 'Sales data retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 4 â€” GET /api/admin/analytics/top-items
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  results = db.session.query(
    FoodItem.id,
    FoodItem.name,
    FoodItem.category,
    func.sum(OrderItem.qty).label('sold'),
    func.sum(OrderItem.subtotal).label('revenue')
  ).join(
    OrderItem, OrderItem.food_id == FoodItem.id
  ).join(
    Order, Order.id == OrderItem.order_id
  ).filter(
    Order.status != 'cancelled'
  ).group_by(
    FoodItem.id,
    FoodItem.name,
    FoodItem.category
  ).order_by(
    func.sum(OrderItem.qty).desc()
  ).limit(5).all()

  Calculate total revenue for share %:
    total_rev = sum(
      float(r.revenue) for r in results) or 1

  Build items list with rank + share:
    items = []
    for i, row in enumerate(results):
      rev   = float(row.revenue)
      share = round((rev / total_rev) * 100, 1)
      items.append({
        'rank':     i + 1,
        'name':     row.name,
        'category': row.category,
        'sold':     int(row.sold),
        'revenue':  round_decimal(rev),
        'share':    share
      })

Response:
  return success({'items': items},
    'Top items retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 5 â€” GET /api/admin/alerts
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  Build alerts list dynamically from DB state.
  Max 10 alerts returned, most critical first.

  alerts = []

  Check 1 â€” Low stock items:
    low_items = db.session.query(
      FoodItem.name, Inventory.current_stock,
      Inventory.reorder_level
    ).join(Inventory).filter(
      Inventory.current_stock < Inventory.reorder_level,
      Inventory.current_stock > 0
    ).limit(3).all()

    For each:
      alerts.append({
        'type':    'warn',
        'message': f'{item.name} is running low
          ({item.current_stock} remaining)',
        'time':    'Now'
      })

  Check 2 â€” Out of stock items:
    out_items = db.session.query(FoodItem.name
    ).join(Inventory).filter(
      Inventory.current_stock == 0,
      FoodItem.available == True
    ).limit(2).all()

    For each:
      alerts.append({
        'type':    'error',
        'message': f'{item.name} is out of stock
          but still marked available',
        'time':    'Now'
      })

  Check 3 â€” Pending orders spike:
    pending_count = Order.query.filter_by(
      status='pending'
    ).count()

    If pending_count > 20:
      alerts.append({
        'type':    'warn',
        'message': f'{pending_count} orders
          are currently pending',
        'time':    'Now'
      })

  Check 4 â€” AI model status:
    ai = AiModelStatus.get_current()
    If ai and ai.status == 'degraded':
      alerts.append({
        'type':    'error',
        'message': 'AI recommendation engine
          is in degraded state',
        'time': to_relative_time(ai.updated_at)
      })

  Check 5 â€” High risk new users today:
    today_start = datetime.utcnow().replace(
      hour=0, minute=0, second=0)
    high_risk_new = User.query.filter(
      User.joined_at >= today_start,
      User.risk_level == 'high'
    ).count()

    If high_risk_new > 0:
      alerts.append({
        'type':    'info',
        'message': f'{high_risk_new} high-risk
          user(s) registered today',
        'time':    'Today'
      })

Response:
  return success({
    'alerts': alerts[:10]
  }, 'Alerts retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test all 5 endpoints with curl:

  TOKEN = (login and get token)

  curl -H "Authorization: Bearer $TOKEN"
    http://localhost:5000/api/admin/overview

  curl -H "Authorization: Bearer $TOKEN"
    http://localhost:5000/api/admin/analytics/orders-by-hour-today

  curl -H "Authorization: Bearer $TOKEN"
    "http://localhost:5000/api/admin/analytics/sales?period=7d"

  curl -H "Authorization: Bearer $TOKEN"
    http://localhost:5000/api/admin/analytics/top-items

  curl -H "Authorization: Bearer $TOKEN"
    http://localhost:5000/api/admin/alerts

  All must return { success: true }
  All must return 401 without token
  All must return 403 for USER role

RULES:
  - func.coalesce() on all SUM queries
    (prevents None when no data exists)
  - All date comparisons use UTC
  - Revenue always excludes cancelled orders
  - 90d sales groups by week not by day
    (too many labels otherwise)
  - Alerts built from live DB state â€” no caching
  - No hardcoded test data anywhere
```

---
---

## ğŸ”· WEEK 2 DAY 2 â€” Food Management Routes

```
Build Week 2 Day 2 food management routes for
Flask Admin Backend of Smart Canteen System.

All Week 1 + Week 2 Day 1 complete.

Day 2 covers ONLY:
  GET    /api/admin/foods
  POST   /api/admin/foods
  PUT    /api/admin/foods/:id
  DELETE /api/admin/foods/:id
  PUT    /api/admin/foods/:id/availability

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ foods/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.foods.routes import foods_bp
  app.register_blueprint(foods_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BLUEPRINT + CONSTANTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

foods_bp = Blueprint('foods', __name__)

FOOD_CATEGORIES = [
  'Meals', 'Snacks', 'Beverages',
  'Desserts', 'Healthy'
]

All imports:
  from flask import Blueprint, request
  from flask_jwt_extended import jwt_required
  from datetime import datetime
  from extensions import db
  from models import FoodItem, Inventory, OrderItem
  from middleware import (require_min_role,
    log_create, log_update, log_delete)
  from utils import (success, error, created,
    no_content, not_found, unprocessable,
    RequestValidator, sanitize_string,
    round_decimal, to_iso)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/foods
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  foods = FoodItem.query.options(
    db.joinedload(FoodItem.inventory)
  ).order_by(FoodItem.created_at.desc()).all()

  Return list with inventory data joined:
    return success({
      'foods': [f.to_table_dict() for f in foods]
    }, 'Foods retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” POST /api/admin/foods
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Validation:
  data = request.get_json()
  v = RequestValidator(data)
  v.required('name','category','calories',
             'sugar','protein') \
   .string('name', min_len=2, max_len=100) \
   .enum('category', FOOD_CATEGORIES) \
   .number('calories', min_val=0) \
   .number('sugar', min_val=0) \
   .number('protein', min_val=0) \
   .number('fat', min_val=0, required=False) \
   .number('stock', min_val=0, required=False) \
   .url('image_url', required=False)

  if not v.is_valid():
    return error('Validation failed', 422,
      errors=v.get_errors())

Logic:
  Check name uniqueness:
    existing = FoodItem.query.filter(
      func.lower(FoodItem.name) ==
        func.lower(data['name'].strip())
    ).first()
    If existing:
      return conflict(
        f'Food item "{data["name"]}" already exists')

  Create food:
    food = FoodItem(
      name        = sanitize_string(data['name']),
      category    = data['category'],
      calories    = float(data['calories']),
      sugar       = float(data['sugar']),
      protein     = float(data['protein']),
      fat         = float(data.get('fat', 0)),
      image_url   = data.get('image_url'),
      description = sanitize_string(
        data.get('description'), max_length=500),
      available   = bool(data.get('available', True))
    )
    db.session.add(food)
    db.session.flush()
      â† flush to get food.id without committing

  Create inventory row:
    inv = Inventory(
      food_id       = food.id,
      current_stock = int(data.get('stock', 0)),
      reorder_level = int(data.get(
        'reorder_level', 10))
    )
    db.session.add(inv)
    db.session.commit()

  Audit:
    log_create('food_items', food.id, food.to_dict())

  Return:
    return created(food.to_table_dict(),
      'Food item created')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” PUT /api/admin/foods/:id
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  food = FoodItem.query.options(
    db.joinedload(FoodItem.inventory)
  ).filter_by(id=food_id).first()
  If not food: return not_found('Food item')

  Capture before state:
    before = food.to_dict()

  data = request.get_json()

  Validate only fields present in request:
    v = RequestValidator(data)
    If 'name' in data:
      v.string('name', min_len=2, max_len=100)
    If 'category' in data:
      v.enum('category', FOOD_CATEGORIES)
    If 'calories' in data:
      v.number('calories', min_val=0)
    If 'sugar' in data:
      v.number('sugar', min_val=0)
    If 'protein' in data:
      v.number('protein', min_val=0)
    If 'fat' in data:
      v.number('fat', min_val=0, required=False)
    If 'image_url' in data:
      v.url('image_url', required=False)

    if not v.is_valid():
      return error('Validation failed', 422,
        errors=v.get_errors())

  Apply updates (only fields present):
    if 'name' in data:
      food.name = sanitize_string(data['name'])
    if 'category' in data:
      food.category = data['category']
    if 'calories' in data:
      food.calories = float(data['calories'])
    if 'sugar' in data:
      food.sugar = float(data['sugar'])
    if 'protein' in data:
      food.protein = float(data['protein'])
    if 'fat' in data:
      food.fat = float(data['fat'])
    if 'image_url' in data:
      food.image_url = data['image_url'] or None
    if 'description' in data:
      food.description = sanitize_string(
        data['description'], 500)
    if 'available' in data:
      food.available = bool(data['available'])

    food.updated_at = datetime.utcnow()
    db.session.commit()

  Audit:
    log_update('food_items', food.id,
      before, food.to_dict())

  Return:
    return success(food.to_table_dict(),
      'Food item updated')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 4 â€” DELETE /api/admin/foods/:id
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  food = FoodItem.query.filter_by(
    id=food_id).first()
  If not food: return not_found('Food item')

  Safety check â€” active orders:
    active_order_count = db.session.query(
      func.count(OrderItem.id)
    ).join(Order).filter(
      OrderItem.food_id == food_id,
      Order.status == 'pending'
    ).scalar()

    If active_order_count > 0:
      return unprocessable(
        f'Cannot delete "{food.name}". '
        f'It appears in {active_order_count} '
        f'pending order(s). Complete or cancel '
        f'those orders first.'
      )

  Capture for audit before delete:
    deleted_data = food.to_dict()

  Delete (cascade removes inventory row):
    db.session.delete(food)
    db.session.commit()

  Audit:
    log_delete('food_items', food_id,
      deleted_data)

  Return:
    return no_content('Food item deleted and '
      'removed from recommendations')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 5 â€” PUT /api/admin/foods/:id/availability
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  food = FoodItem.query.filter_by(
    id=food_id).first()
  If not food: return not_found('Food item')

  data = request.get_json()
  If 'available' not in data:
    return error('"available" field required', 400)
  If not isinstance(data['available'], bool):
    return error('"available" must be true or false')

  before = {'available': food.available}
  food.available  = data['available']
  food.updated_at = datetime.utcnow()
  db.session.commit()

  log_update('food_items', food.id,
    before, {'available': food.available})

  status_msg = 'available' if food.available \
    else 'unavailable'
  return success(food.to_table_dict(),
    f'"{food.name}" marked as {status_msg}')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - db.session.flush() before commit when
    you need the generated ID immediately
  - Partial updates: only update fields
    present in request body
  - Delete blocked if pending orders exist
  - Name uniqueness check is case-insensitive
  - All audit logs written AFTER db.session.commit()
  - Cascade delete handles inventory row automatically
  - sanitize_string() on all text inputs
```

---
---

## ğŸ”· WEEK 2 DAY 3 â€” Inventory Routes

```
Build Week 2 Day 3 inventory routes for
Flask Admin Backend of Smart Canteen System.

All Week 1 + Week 2 Days 1-2 complete.

Day 3 covers ONLY:
  GET /api/admin/inventory
  PUT /api/admin/inventory/:food_id

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ inventory/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.inventory.routes import inventory_bp
  app.register_blueprint(inventory_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/inventory
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  Query all inventory with food data joined:
    items = db.session.query(
      Inventory, FoodItem
    ).join(
      FoodItem, FoodItem.id == Inventory.food_id
    ).order_by(
      Inventory.current_stock.asc()
    ).all()
    â† ASC puts out-of-stock first

  Calculate summary counts:
    total      = len(items)
    low_stock  = sum(1 for inv, _ in items
      if 0 < inv.current_stock < inv.reorder_level)
    out_stock  = sum(1 for inv, _ in items
      if inv.current_stock == 0)

  Build items list:
    result = []
    for inv, food in items:
      result.append({
        'food_id':       str(food.id),
        'name':          food.name,
        'category':      food.category,
        'current_stock': inv.current_stock,
        'reorder_level': inv.reorder_level,
        'status':        inv.get_status(),
        'last_updated':  to_iso(inv.last_updated),
        'last_updated_relative':
          to_relative_time(inv.last_updated)
      })

Response:
  return success({
    'summary': {
      'total':      total,
      'lowStock':   low_stock,
      'outOfStock': out_stock
    },
    'items': result
  }, 'Inventory retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” PUT /api/admin/inventory/:food_id
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  Find inventory row by food_id:
    inv = Inventory.query.filter_by(
      food_id=food_id).first()
    If not inv:
      return not_found('Inventory record')

  Also load food for response:
    food = FoodItem.query.filter_by(
      id=food_id).first()
    If not food:
      return not_found('Food item')

  data = request.get_json()

  Validate quantity:
    v = RequestValidator(data)
    v.required('quantity') \
     .number('quantity', min_val=0, integer=True)
    if not v.is_valid():
      return error('Validation failed', 422,
        errors=v.get_errors())

  Capture before state:
    before = {
      'current_stock': inv.current_stock,
      'status':        inv.get_status()
    }

  Apply update:
    from middleware import get_current_admin
    admin = get_current_admin()

    inv.current_stock = int(data['quantity'])
    inv.last_updated  = datetime.utcnow()
    inv.updated_by    = admin.id if admin else None
    db.session.commit()

  Capture after state:
    after = {
      'current_stock': inv.current_stock,
      'status':        inv.get_status()
    }

  Audit:
    log_update('inventory', food_id,
      before, after)

  Build response item:
    item = {
      'food_id':       str(food.id),
      'name':          food.name,
      'category':      food.category,
      'current_stock': inv.current_stock,
      'reorder_level': inv.reorder_level,
      'status':        inv.get_status(),
      'last_updated':  to_iso(inv.last_updated),
      'last_updated_relative':
        to_relative_time(inv.last_updated)
    }

  Return:
    return success(item,
      f'Stock updated for "{food.name}"')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - food_id in URL path is the inventory lookup key
    not inv.id
  - updated_by must reference admin performing action
    capture from get_current_admin()
  - Integer validation strictly enforced on quantity
  - Status recalculated from model method after update
  - Inventory query always orders by stock ASC
    so frontend gets worst items first
  - Both summary + items returned in single GET call
    saves frontend from making two requests
```

---
---

## ğŸ”· WEEK 2 DAY 4 â€” Orders Routes

```
Build Week 2 Day 4 orders routes for
Flask Admin Backend of Smart Canteen System.

All Week 1 + Week 2 Days 1-3 complete.

Day 4 covers ONLY:
  GET /api/admin/orders
  PUT /api/admin/orders/:id/status

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ orders/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.orders.routes import orders_bp
  app.register_blueprint(orders_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/orders
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Query params:
  status = request.args.get('status', 'all')
  Allowed: 'all','pending','completed','cancelled'

Logic â€” Summary (always all statuses):
  from sqlalchemy import case

  summary_rows = db.session.query(
    Order.status,
    func.count(Order.id).label('count')
  ).group_by(Order.status).all()

  summary = {
    'total': 0,
    'pending': 0,
    'completed': 0,
    'cancelled': 0
  }
  for row in summary_rows:
    summary[row.status] = row.count
    summary['total'] += row.count

Logic â€” Orders query:
  query = db.session.query(Order).options(
    db.joinedload(Order.user),
    db.joinedload(Order.items).joinedload(
      OrderItem.food)
  ).order_by(Order.created_at.desc())

  If status != 'all':
    query = query.filter(Order.status == status)

  orders = query.limit(100).all()
    â† Limit to 100 for performance
    â† Full pagination added if needed in Week 3

Build response per order:
  def build_order_dict(order):
    items = []
    for item in order.items:
      items.append({
        'food_id':   str(item.food_id),
        'name':      item.food.name if item.food
          else 'Unknown',
        'category':  item.food.category if item.food
          else None,
        'qty':       item.qty,
        'unit_price':round_decimal(item.unit_price),
        'subtotal':  round_decimal(item.subtotal),
        'health_flag': item.health_flag
      })

    customer = {}
    if order.user:
      name = order.user.name
      initials = ''.join(
        p[0].upper() for p in name.split()[:2])
      customer = {
        'name':            name,
        'email':           order.user.email,
        'avatar_initials': initials
      }

    return {
      'id':           str(order.id),
      'order_number': order.order_number,
      'customer':     customer,
      'items':        items,
      'total':        round_decimal(order.total),
      'status':       order.status,
      'payment_method':  order.payment_method,
      'delivery_type':   order.delivery_type,
      'special_instructions':
        order.special_instructions,
      'created_at':   to_iso(order.created_at),
      'created_at_display':
        to_display_datetime(order.created_at),
      'created_at_relative':
        to_relative_time(order.created_at)
    }

Response:
  return success({
    'summary': summary,
    'orders':  [build_order_dict(o)
      for o in orders]
  }, 'Orders retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” PUT /api/admin/orders/:id/status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  order = Order.query.filter_by(
    id=order_id).first()
  If not order: return not_found('Order')

  data = request.get_json()
  new_status = data.get('status')

  Validate new_status:
    If new_status not in ['completed','cancelled']:
      return error(
        'Status must be "completed" or "cancelled"',
        400)

  Validate transition:
    If not order.can_change_status(new_status):
      return unprocessable(
        f'Order #{order.order_number} '
        f'is already {order.status} '
        f'and cannot be changed.')

  Capture before:
    old_status = order.status

  Apply update:
    order.status     = new_status
    order.updated_at = datetime.utcnow()
    db.session.commit()

  Audit:
    log_status_change('orders', order.id,
      old_status, new_status)

  Return:
    return success({
      'id':           str(order.id),
      'order_number': order.order_number,
      'status':       order.status,
      'updated_at':   to_iso(order.updated_at)
    }, f'Order {order.order_number} '
       f'marked as {new_status}')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - Summary always returns all 4 counts
    regardless of status filter
  - order.can_change_status() from model method
    enforces transition rules â€” don't duplicate
    that logic in the route
  - joinedload for user + items + food prevents
    N+1 query problem
  - 100 order limit on GET â€” acceptable for now
    full pagination added in analytics week
  - health_flag on order items already set
    when orders are created by user system
    admin just reads it â€” never sets it
  - to_display_datetime() + to_relative_time()
    both returned so frontend can use either
```

---
---

## ğŸ”· WEEK 2 DAY 5 â€” Users Routes

```
Build Week 2 Day 5 users routes for
Flask Admin Backend of Smart Canteen System.

All Week 1 + Week 2 Days 1-4 complete.

Day 5 covers ONLY:
  GET /api/admin/users
  PUT /api/admin/users/:id

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ users/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.users.routes import users_bp
  app.register_blueprint(users_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/users
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic â€” Summary:
  total       = User.query.filter_by(
    role='USER').count()
  active      = User.query.filter_by(
    role='USER', status='active').count()
  deactivated = User.query.filter_by(
    role='USER', status='inactive').count()
  high_risk   = User.query.filter_by(
    role='USER', risk_level='high').count()

Logic â€” Users with order stats:
  users = User.query.filter_by(
    role='USER'
  ).order_by(User.joined_at.desc()).all()

  For each user, calculate order stats
  using subquery:

    order_stats_query = db.session.query(
      Order.user_id,
      func.count(Order.id).label('total_orders'),
      func.coalesce(
        func.sum(Order.total), 0
      ).label('total_spent'),
      func.coalesce(
        func.avg(Order.total), 0
      ).label('avg_order_value')
    ).filter(
      Order.status != 'cancelled'
    ).group_by(Order.user_id).subquery()

    Use LEFT OUTER JOIN users with this subquery
    to get stats in one query rather than
    per-user queries (prevents N+1).

  For each user build dict:
    def build_user_dict(user, stats):
      return {
        'id':         str(user.id),
        'name':       user.name,
        'email':      user.email,
        'role':       user.role,
        'risk_level': user.risk_level,
        'risk_score': user.risk_score,
        'conditions': user.conditions or [],
        'dietary_preferences':
          user.dietary_prefs or [],
        'status':     user.status,
        'joined_at':  to_iso(user.joined_at),
        'joined_display':
          to_display_date(user.joined_at),
        'last_active': to_iso(user.last_active),
        'last_active_relative':
          to_relative_time(user.last_active),
        'order_stats': {
          'total_orders':    stats.total_orders
            if stats else 0,
          'total_spent':     round_decimal(
            stats.total_spent) if stats else 0,
          'avg_order_value': round_decimal(
            stats.avg_order_value) if stats else 0
        },
        'ai_insights': _get_ai_insights(user.id)
      }

  def _get_ai_insights(user_id):
    from models import AiRecommendationLog
    from sqlalchemy import case

    total = AiRecommendationLog.query.filter_by(
      user_id=user_id).count()

    accepted = AiRecommendationLog.query.filter_by(
      user_id=user_id,
      user_action='accepted').count()

    compliance = round(
      (accepted / total * 100) if total > 0 else 0,
      1)

    top_food = db.session.query(
      FoodItem.category,
      func.count(AiRecommendationLog.id).label('cnt')
    ).join(
      FoodItem,
      FoodItem.id == AiRecommendationLog.food_id
    ).filter(
      AiRecommendationLog.user_id == user_id
    ).group_by(
      FoodItem.category
    ).order_by(
      func.count(AiRecommendationLog.id).desc()
    ).first()

    return {
      'top_category':    top_food.category
        if top_food else None,
      'flagged_items':   0,
        â† populated by AI service in production
      'compliance_rate': compliance
    }

Response:
  return success({
    'summary': {
      'total':       total,
      'active':      active,
      'deactivated': deactivated,
      'highRisk':    high_risk
    },
    'users': users_list
  }, 'Users retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” PUT /api/admin/users/:id
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('MANAGER')

Logic:
  target_user = User.query.filter_by(
    id=user_id).first()
  If not target_user:
    return not_found('User')

  data     = request.get_json()
  admin    = get_current_admin()
  before   = target_user.to_dict()

  Determine operation type:
    has_role   = 'role' in data
    has_active = 'active' in data

  If both provided:
    return error(
      'Send role change and status change '
      'as separate requests', 400)

  OPERATION A â€” Role Change:
    If has_role:
      RBAC: only SUPER_ADMIN can change roles
        If admin.role != 'SUPER_ADMIN':
          return forbidden(
            'Only SUPER_ADMIN can change roles')

      new_role = data['role']
      Validate:
        If new_role not in [
          'USER','ANALYST','MANAGER','SUPER_ADMIN']:
          return error('Invalid role', 400)
        If new_role == target_user.role:
          return error(
            'User already has this role', 400)

      Safety: cannot demote last SUPER_ADMIN:
        If target_user.role == 'SUPER_ADMIN':
          super_count = User.query.filter_by(
            role='SUPER_ADMIN',
            status='active').count()
          If super_count <= 1:
            return unprocessable(
              'Cannot change role of the '
              'last active SUPER_ADMIN')

      Apply:
        target_user.role = new_role
        db.session.commit()
        log_update('users', user_id, before,
          target_user.to_dict())
        return success(
          target_user.to_dict(),
          f'Role updated to {new_role}')

  OPERATION B â€” Status Change (activate/deactivate):
    If has_active:
      new_active = bool(data['active'])
      new_status = 'active' if new_active \
        else 'inactive'

      Safety: cannot deactivate self:
        If str(target_user.id) == str(admin.id):
          return unprocessable(
            'You cannot deactivate your own account')

      Safety: cannot deactivate last SUPER_ADMIN:
        If target_user.role == 'SUPER_ADMIN' \
          and not new_active:
          super_count = User.query.filter_by(
            role='SUPER_ADMIN',
            status='active').count()
          If super_count <= 1:
            return unprocessable(
              'Cannot deactivate the last '
              'active SUPER_ADMIN')

      Apply:
        target_user.status = new_status
        db.session.commit()
        log_update('users', user_id, before,
          target_user.to_dict())

        action = 'activated' if new_active \
          else 'deactivated'
        return success(
          target_user.to_dict(),
          f'{target_user.name} has been {action}')

  If neither field provided:
    return error(
      'Provide either "role" or "active" field',
      400)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - GET users filters role='USER' only
    Admin accounts managed separately
  - AI insights use subquery â€” not per-user loop
    (N+1 prevention critical here)
  - Role change and status change in same
    PUT endpoint but validated separately
    One request = one operation only
  - Last SUPER_ADMIN protection on both
    role change AND deactivation
  - Cannot deactivate own account â€” ever
  - RBAC check for role changes happens
    inside route logic (not just decorator)
    because it depends on operation type
  - to_display_date() for joined_at
    to_relative_time() for last_active
    both returned for frontend flexibility
```

---
---

## ğŸ”· WEEK 3 DAY 1 â€” Analytics Routes (Part 1)

```
Build Week 3 Day 1 analytics routes (Part 1) for
Flask Admin Backend of Smart Canteen System.

All Week 1 + Week 2 complete:
  App factory, models, auth, rbac, audit,
  utils all done.
  Dashboard, foods, inventory, orders,
  users routes all done.

Day 1 of Week 3 covers ONLY:
  GET /api/admin/analytics/summary
  GET /api/admin/analytics/revenue-by-category
  GET /api/admin/analytics/popular-foods
  GET /api/admin/analytics/category-heatmap
  GET /api/admin/analytics/peak-hours

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ analytics/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.analytics.routes import analytics_bp
  app.register_blueprint(analytics_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SHARED SETUP IN routes.py:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

All imports:
  from flask import Blueprint, request
  from flask_jwt_extended import jwt_required
  from datetime import datetime, timedelta
  from sqlalchemy import func, extract, case
  from extensions import db
  from models import (Order, OrderItem, FoodItem,
    User, AiRecommendationLog)
  from middleware import require_min_role
  from utils import (success, error,
    get_date_range_or_default,
    get_previous_period, calculate_change,
    round_decimal, to_iso)

analytics_bp = Blueprint('analytics', __name__)

SHARED HELPER â€” get_date_filters():
  def get_date_filters():
    """
    Reads from + to from request.args.
    Returns (from_dt, to_dt) datetime objects.
    Defaults to last 30 days if not provided.
    Called at top of every analytics endpoint.
    """
    from_str = request.args.get('from')
    to_str   = request.args.get('to')
    return get_date_range_or_default(
      from_str, to_str, default_days=30)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/analytics/summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()
  prev_from, prev_to = get_previous_period(
    from_dt, to_dt)

  def get_period_stats(start, end):
    """
    Returns revenue, order count, avg order value
    for a given date range.
    Excludes cancelled orders.
    """
    result = db.session.query(
      func.coalesce(
        func.sum(Order.total), 0
      ).label('revenue'),
      func.count(Order.id).label('orders'),
      func.coalesce(
        func.avg(Order.total), 0
      ).label('avg_value')
    ).filter(
      Order.created_at.between(start, end),
      Order.status != 'cancelled'
    ).first()
    return result

  current  = get_period_stats(from_dt, to_dt)
  previous = get_period_stats(prev_from, prev_to)

  New users in period:
    current_users = User.query.filter(
      User.joined_at.between(from_dt, to_dt),
      User.role == 'USER'
    ).count()
    previous_users = User.query.filter(
      User.joined_at.between(prev_from, prev_to),
      User.role == 'USER'
    ).count()

Response:
  return success({
    'revenue': {
      'value':  round_decimal(current.revenue),
      'change': calculate_change(
        float(current.revenue),
        float(previous.revenue))
    },
    'orders': {
      'value':  current.orders,
      'change': calculate_change(
        current.orders, previous.orders)
    },
    'avg_order_value': {
      'value':  round_decimal(current.avg_value),
      'change': calculate_change(
        float(current.avg_value),
        float(previous.avg_value))
    },
    'new_users': {
      'value':  current_users,
      'change': calculate_change(
        current_users, previous_users)
    }
  }, 'Summary retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” GET /api/admin/analytics/revenue-by-category
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  results = db.session.query(
    FoodItem.category,
    func.coalesce(
      func.sum(OrderItem.subtotal), 0
    ).label('revenue')
  ).join(
    OrderItem, OrderItem.food_id == FoodItem.id
  ).join(
    Order, Order.id == OrderItem.order_id
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled'
  ).group_by(
    FoodItem.category
  ).order_by(
    func.sum(OrderItem.subtotal).desc()
  ).all()

  All 5 categories must appear in response
  even if value is 0:
    ALL_CATEGORIES = [
      'Meals','Snacks','Beverages',
      'Desserts','Healthy'
    ]
    cat_map = {
      row.category: float(row.revenue)
      for row in results
    }
    categories = ALL_CATEGORIES
    values = [
      round_decimal(cat_map.get(c, 0))
      for c in ALL_CATEGORIES
    ]

Response:
  return success({
    'categories': categories,
    'values':     values
  }, 'Revenue by category retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” GET /api/admin/analytics/popular-foods
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  results = db.session.query(
    FoodItem.id,
    FoodItem.name,
    FoodItem.category,
    func.sum(OrderItem.qty).label('count'),
    func.sum(OrderItem.subtotal).label('revenue')
  ).join(
    OrderItem, OrderItem.food_id == FoodItem.id
  ).join(
    Order, Order.id == OrderItem.order_id
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled'
  ).group_by(
    FoodItem.id, FoodItem.name, FoodItem.category
  ).order_by(
    func.sum(OrderItem.qty).desc()
  ).limit(10).all()

  foods = [{
    'name':     row.name,
    'category': row.category,
    'count':    int(row.count),
    'revenue':  round_decimal(row.revenue)
  } for row in results]

Response:
  return success({
    'foods': foods
  }, 'Popular foods retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 4 â€” GET /api/admin/analytics/category-heatmap
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  PostgreSQL DOW: 0=Sunday, 1=Monday, ..., 6=Saturday
  Remap to Mon-Sun: Mon=0 ... Sun=6

  results = db.session.query(
    FoodItem.category,
    extract('dow', Order.created_at).label('dow'),
    func.count(Order.id).label('order_count')
  ).join(
    OrderItem, OrderItem.food_id == FoodItem.id
  ).join(
    Order, Order.id == OrderItem.order_id
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled'
  ).group_by(
    FoodItem.category,
    extract('dow', Order.created_at)
  ).all()

  Build 5Ã—7 matrix (categories Ã— days):
    ALL_CATEGORIES = [
      'Meals','Snacks','Beverages',
      'Desserts','Healthy'
    ]
    DAYS = ['Mon','Tue','Wed','Thu',
            'Fri','Sat','Sun']

    DOW_REMAP:
      PostgreSQL DOW 1=Mon...6=Sat, 0=Sun
      Remap to index: Mon=0...Sun=6
      dow_to_index = {
        1:0, 2:1, 3:2, 4:3,
        5:4, 6:5, 0:6
      }

    Initialize matrix as zeros:
      matrix = {
        cat: [0]*7
        for cat in ALL_CATEGORIES
      }

    Fill from results:
      for row in results:
        if row.category in matrix:
          day_idx = dow_to_index.get(
            int(row.dow), 0)
          matrix[row.category][day_idx] = (
            int(row.order_count))

    Convert to 2D array (rows = categories):
      data = [matrix[cat]
        for cat in ALL_CATEGORIES]

Response:
  return success({
    'days':       DAYS,
    'categories': ALL_CATEGORIES,
    'data':       data
  }, 'Heatmap data retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 5 â€” GET /api/admin/analytics/peak-hours
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  results = db.session.query(
    extract('hour', Order.created_at).label('hour'),
    func.count(Order.id).label('count')
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled'
  ).group_by(
    extract('hour', Order.created_at)
  ).all()

  All 24 hours must appear â€” fill missing with 0:
    hour_map = {h: 0 for h in range(24)}
    for row in results:
      hour_map[int(row.hour)] = int(row.count)

    hours  = list(range(24))
    counts = [hour_map[h] for h in hours]

Response:
  return success({
    'hours':  hours,
    'counts': counts
  }, 'Peak hours retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - All 5 categories always in revenue response
    even if zero â€” frontend expects fixed structure
  - All 24 hours always in peak-hours response
  - DOW remapping is critical â€” PostgreSQL uses
    Sunday=0 but frontend expects Monday=0
  - func.coalesce() on every SUM/AVG to prevent
    None when no data in range
  - calculate_change() handles division by zero
    already â€” no extra guard needed
  - Date filters applied to EVERY endpoint
  - Cancelled orders excluded from all revenue
    calculations throughout analytics
```

---
---

## ğŸ”· WEEK 3 DAY 2 â€” Analytics Routes (Part 2)

```
Build Week 3 Day 2 analytics routes (Part 2) for
Flask Admin Backend of Smart Canteen System.

Week 3 Day 1 analytics (Part 1) is complete:
  summary, revenue-by-category,
  popular-foods, category-heatmap,
  peak-hours all done.

Day 2 covers the remaining analytics endpoints:
  GET /api/admin/analytics/disease-distribution
  GET /api/admin/analytics/risk-trends
  GET /api/admin/analytics/top-spenders
  GET /api/admin/analytics/ai-impact

Add all 4 endpoints to the EXISTING
admin/analytics/routes.py file.
Do not create new files today.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/analytics/disease-distribution
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Note:
  This endpoint does NOT use date filters.
  Disease distribution reflects current
  user base â€” not a time-series metric.

Logic:
  PostgreSQL UNNEST to expand conditions array:

  from sqlalchemy import text

  query = text("""
    SELECT
      condition,
      COUNT(*) as user_count
    FROM (
      SELECT UNNEST(conditions) as condition
      FROM users
      WHERE role = 'USER'
        AND status = 'active'
        AND conditions IS NOT NULL
        AND array_length(conditions, 1) > 0
    ) sub
    GROUP BY condition
    ORDER BY user_count DESC
    LIMIT 6
  """)

  results = db.session.execute(query).fetchall()

  Total active users for percentage:
    total_users = User.query.filter_by(
      role='USER', status='active').count()

  Build response:
    conditions = []
    counts     = []
    for row in results:
      conditions.append(row.condition)
      counts.append(row.user_count)

Response:
  return success({
    'conditions':  conditions,
    'counts':      counts,
    'total_users': total_users
  }, 'Disease distribution retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” GET /api/admin/analytics/risk-trends
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  Strategy:
    Since we track risk_level per user at
    current state, we approximate trends by
    looking at when users joined AND their
    current risk level.
    Group by month of join date.

  results = db.session.query(
    func.date_trunc('month',
      User.joined_at).label('month'),
    User.risk_level,
    func.count(User.id).label('count')
  ).filter(
    User.joined_at.between(from_dt, to_dt),
    User.role == 'USER'
  ).group_by(
    func.date_trunc('month', User.joined_at),
    User.risk_level
  ).order_by('month').all()

  Build parallel arrays:
    Collect all unique months sorted:
      months = sorted(set(
        row.month for row in results))

    Initialize per-level maps:
      low_map  = {m: 0 for m in months}
      mod_map  = {m: 0 for m in months}
      high_map = {m: 0 for m in months}

    Fill from results:
      for row in results:
        if row.risk_level == 'low':
          low_map[row.month]  += row.count
        elif row.risk_level == 'moderate':
          mod_map[row.month]  += row.count
        elif row.risk_level == 'high':
          high_map[row.month] += row.count

    Format labels as 'Jan 2025', 'Feb 2025' etc:
      labels = [
        m.strftime('%b %Y') for m in months
      ]

    Build parallel count arrays:
      low      = [low_map[m]  for m in months]
      moderate = [mod_map[m]  for m in months]
      high     = [high_map[m] for m in months]

  Handle empty case:
    If no months found (no users in range):
      Return labels=[], low=[], moderate=[], high=[]

Response:
  return success({
    'labels':   labels,
    'low':      low,
    'moderate': moderate,
    'high':     high
  }, 'Risk trends retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” GET /api/admin/analytics/top-spenders
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  results = db.session.query(
    User.id,
    User.name,
    User.email,
    func.count(Order.id).label('order_count'),
    func.coalesce(
      func.sum(Order.total), 0
    ).label('total_spent')
  ).join(
    Order, Order.user_id == User.id
  ).filter(
    Order.created_at.between(from_dt, to_dt),
    Order.status != 'cancelled',
    User.role == 'USER'
  ).group_by(
    User.id, User.name, User.email
  ).order_by(
    func.sum(Order.total).desc()
  ).limit(5).all()

  Build spenders list:
    spenders = []
    for i, row in enumerate(results):
      name     = row.name
      initials = ''.join(
        p[0].upper()
        for p in name.split()[:2]
      )
      spenders.append({
        'rank':      i + 1,
        'id':        str(row.id),
        'name':      name,
        'email':     row.email,
        'initials':  initials,
        'orders':    row.order_count,
        'total':     round_decimal(row.total_spent)
      })

Response:
  return success({
    'spenders': spenders
  }, 'Top spenders retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 4 â€” GET /api/admin/analytics/ai-impact
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  from_dt, to_dt = get_date_filters()

  Total recommendations served:
    total_served = AiRecommendationLog.query.filter(
      AiRecommendationLog.created_at.between(
        from_dt, to_dt)
    ).count()

  Accepted count:
    accepted = AiRecommendationLog.query.filter(
      AiRecommendationLog.created_at.between(
        from_dt, to_dt),
      AiRecommendationLog.user_action == 'accepted'
    ).count()

  Acceptance rate:
    acceptance_rate = round(
      (accepted / total_served * 100)
      if total_served > 0 else 0, 1)

  Health improvement rate:
    Metric: % of high-risk users who accepted
    at least one healthy food recommendation
    in the period.

    high_risk_users = User.query.filter_by(
      risk_level='high',
      role='USER',
      status='active'
    ).count()

    high_risk_accepted = db.session.query(
      func.count(
        func.distinct(
          AiRecommendationLog.user_id))
    ).join(
      User, User.id == AiRecommendationLog.user_id
    ).join(
      FoodItem,
      FoodItem.id == AiRecommendationLog.food_id
    ).filter(
      AiRecommendationLog.created_at.between(
        from_dt, to_dt),
      AiRecommendationLog.user_action == 'accepted',
      FoodItem.category == 'Healthy',
      User.risk_level == 'high'
    ).scalar() or 0

    health_improvement = round(
      (high_risk_accepted / high_risk_users * 100)
      if high_risk_users > 0 else 0, 1)

  Most recommended food item:
    top_food = db.session.query(
      FoodItem.name,
      func.count(
        AiRecommendationLog.id).label('cnt')
    ).join(
      FoodItem,
      FoodItem.id == AiRecommendationLog.food_id
    ).filter(
      AiRecommendationLog.created_at.between(
        from_dt, to_dt)
    ).group_by(
      FoodItem.name
    ).order_by(
      func.count(
        AiRecommendationLog.id).desc()
    ).first()

    top_item = top_food.name if top_food else None

Response:
  return success({
    'served':             total_served,
    'accepted':           accepted,
    'acceptance_rate':    acceptance_rate,
    'health_improvement': health_improvement,
    'top_item':           top_item
  }, 'AI impact retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - disease-distribution: no date filter
    reflects current user state always
  - risk-trends: use date_trunc('month')
    not daily â€” too granular otherwise
  - risk-trends empty state: return empty
    arrays not an error â€” frontend handles
  - top-spenders: USER role only
    admin accounts excluded
  - ai-impact: health_improvement is a
    business metric â€” document formula
    clearly in code comments
  - All percentage calculations: guard
    against division by zero
  - func.distinct() in health improvement
    counts unique users not log entries
```

---
---

## ğŸ”· WEEK 3 DAY 3 â€” AI Monitoring Routes

```
Build Week 3 Day 3 AI monitoring routes for
Flask Admin Backend of Smart Canteen System.

All Week 1, Week 2, Week 3 Days 1-2 complete.

Day 3 covers ONLY:
  GET  /api/admin/ai/status
  GET  /api/admin/ai/features
  GET  /api/admin/ai/accuracy-history
  GET  /api/admin/ai/logs
  GET  /api/admin/ai/training-history
  POST /api/admin/ai/retrain

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ ai_monitor/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.ai_monitor.routes import ai_bp
  app.register_blueprint(ai_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BLUEPRINT SETUP:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ai_bp = Blueprint('ai_monitor', __name__)

All imports:
  from flask import Blueprint, request, current_app
  from flask_jwt_extended import jwt_required
  from datetime import datetime
  from extensions import db
  from models import (AiModelStatus,
    AiTrainingHistory, AiFeatureImportance,
    AiRecommendationLog, FoodItem, User)
  from middleware import (require_min_role,
    require_role, get_current_admin, log_retrain)
  from utils import (success, error, not_found,
    conflict, paginate_query, get_pagination_args,
    to_iso, to_relative_time, round_decimal)
  import threading

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/ai/status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  model = AiModelStatus.get_current()

  If not model:
    Return default status (model not initialized):
      return success({
        'status':            'inactive',
        'version':           None,
        'last_trained':      None,
        'total_predictions': 0,
        'metrics': {
          'accuracy':  None,
          'precision': None,
          'recall':    None,
          'f1':        None
        }
      }, 'AI status retrieved')

Response:
  return success({
    'status':  model.status,
    'version': model.version,
    'last_trained': to_iso(model.last_trained),
    'last_trained_relative':
      to_relative_time(model.last_trained),
    'total_predictions': model.total_predictions,
    'metrics': {
      'accuracy':  round_decimal(
        model.accuracy, 2),
      'precision': round_decimal(
        model.precision_score, 4),
      'recall':    round_decimal(
        model.recall_score, 4),
      'f1':        round_decimal(
        model.f1_score, 4)
    }
  }, 'AI status retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” GET /api/admin/ai/features
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  Get current model version first:
    model = AiModelStatus.get_current()
    version = model.version if model else None

  Query feature importance for current version:
    query = AiFeatureImportance.query
    If version:
      query = query.filter_by(
        model_version=version)
    features = query.order_by(
      AiFeatureImportance.importance.desc()
    ).limit(8).all()

  Build response:
    features_list = [{
      'name':       f.feature_name,
      'importance': round_decimal(f.importance, 4)
    } for f in features]

  Handle empty:
    If no features in DB yet, return defaults:
      DEFAULT_FEATURES = [
        {'name': 'Sugar Level',   'importance': 0.0},
        {'name': 'Calories',      'importance': 0.0},
        {'name': 'Disease Type',  'importance': 0.0},
        {'name': 'Protein',       'importance': 0.0},
        {'name': 'User History',  'importance': 0.0},
        {'name': 'Time of Day',   'importance': 0.0},
        {'name': 'Category',      'importance': 0.0},
        {'name': 'Fat Content',   'importance': 0.0}
      ]
      features_list = DEFAULT_FEATURES

Response:
  return success({
    'features':       features_list,
    'model_version':  version
  }, 'Feature importance retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” GET /api/admin/ai/accuracy-history
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  history = AiTrainingHistory.query.filter_by(
    status='success'
  ).order_by(
    AiTrainingHistory.ended_at.asc()
  ).all()

  Build parallel arrays:
    dates    = []
    accuracy = []
    notes    = []

    for h in history:
      dates.append(
        to_iso(h.ended_at))
      accuracy.append(
        round_decimal(h.accuracy_after, 2)
        if h.accuracy_after else None)
      notes.append(h.notes or '')

Response:
  return success({
    'dates':    dates,
    'accuracy': accuracy,
    'notes':    notes
  }, 'Accuracy history retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 4 â€” GET /api/admin/ai/logs
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Query params:
  page, per_page via get_pagination_args()
  risk    = request.args.get('risk')
  action  = request.args.get('action')
  period  = request.args.get('period', '30d')
  search  = request.args.get('search', '').strip()

Logic:
  from utils import get_period_dates
  from_dt, to_dt = get_period_dates(period)

  query = db.session.query(
    AiRecommendationLog
  ).options(
    db.joinedload(AiRecommendationLog.user),
    db.joinedload(AiRecommendationLog.food)
  ).filter(
    AiRecommendationLog.created_at.between(
      from_dt, to_dt)
  )

  Apply filters:
    If risk:
      query = query.join(
        User,
        User.id == AiRecommendationLog.user_id
      ).filter(User.risk_level == risk)

    If action:
      query = query.filter(
        AiRecommendationLog.user_action == action)

    If search:
      query = query.join(
        User,
        User.id == AiRecommendationLog.user_id
      ).join(
        FoodItem,
        FoodItem.id == AiRecommendationLog.food_id
      ).filter(
        db.or_(
          User.name.ilike(f'%{search}%'),
          FoodItem.name.ilike(f'%{search}%')
        )
      )

  Order by most recent first:
    query = query.order_by(
      AiRecommendationLog.created_at.desc())

  Paginate:
    page, per_page = get_pagination_args()
    items, meta = paginate_query(
      query, page, per_page)

  Build log items:
    def get_confidence_badge(conf):
      if conf is None: return 'unknown'
      if conf > 85:   return 'high'
      if conf >= 60:  return 'medium'
      return 'low'

    logs = [{
      'id':            str(log.id),
      'timestamp':     to_iso(log.created_at),
      'timestamp_relative':
        to_relative_time(log.created_at),
      'user_name':     log.user.name
        if log.user else 'Unknown',
      'user_risk':     log.user.risk_level
        if log.user else None,
      'food_name':     log.food.name
        if log.food else 'Unknown',
      'food_category': log.food.category
        if log.food else None,
      'reason':        log.reason,
      'confidence':    round_decimal(
        log.confidence, 1),
      'confidence_level': get_confidence_badge(
        log.confidence),
      'user_action':   log.user_action,
      'match_score':   log.match_score
    } for log in items]

Response:
  from utils import paginated
  return paginated(logs, meta,
    'Recommendation logs retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 5 â€” GET /api/admin/ai/training-history
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  history = AiTrainingHistory.query.options(
    db.joinedload(
      AiTrainingHistory.triggered_by_user)
  ).order_by(
    AiTrainingHistory.started_at.desc()
  ).limit(20).all()

  items = [{
    'id':               str(h.id),
    'triggered_by':     h.triggered_by_user.name
      if h.triggered_by_user else 'System',
    'date':             to_iso(h.started_at),
    'date_display':     h.started_at.strftime(
      '%-d %b %Y, %-I:%M %p')
      if h.started_at else None,
    'duration':         h.get_duration_formatted(),
    'accuracy_before':  round_decimal(
      h.accuracy_before, 2),
    'accuracy_after':   round_decimal(
      h.accuracy_after, 2),
    'accuracy_delta':   h.get_accuracy_delta(),
    'status':           h.status,
    'notes':            h.notes
  } for h in history]

Response:
  return success({
    'history': items
  }, 'Training history retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 6 â€” POST /api/admin/ai/retrain
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_role('SUPER_ADMIN')
  â† SUPER_ADMIN only â€” exact role not hierarchy

Logic:
  Check not already retraining:
    model = AiModelStatus.get_current()
    If model and model.status == 'retraining':
      return conflict(
        'Model is already retraining. '
        'Please wait for it to complete.')

  Get current accuracy for before snapshot:
    accuracy_before = float(model.accuracy) \
      if model and model.accuracy else None

  Get current admin:
    admin = get_current_admin()

  Create training history record:
    training = AiTrainingHistory(
      triggered_by    = admin.id if admin else None,
      started_at      = datetime.utcnow(),
      accuracy_before = accuracy_before,
      status          = 'in_progress'
    )
    db.session.add(training)

  Update model status to retraining:
    If model:
      model.status     = 'retraining'
      model.updated_at = datetime.utcnow()
    Else:
      model = AiModelStatus(status='retraining')
      db.session.add(model)

  Commit:
    db.session.commit()

  Audit:
    log_retrain(accuracy_before)

  Start background thread:
    thread = threading.Thread(
      target=_run_retrain_task,
      args=(
        str(training.id),
        current_app._get_current_object()
      ),
      daemon=True
    )
    thread.start()

Response:
  return success({
    'training_id': str(training.id),
    'message':     'Retraining started',
    'status':      'retraining'
  }, 'Model retraining initiated', 202)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BACKGROUND TASK â€” _run_retrain_task()
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _run_retrain_task(training_id, app):
  """
  Runs in background thread.
  Uses app context to access DB.
  Simulates ML retraining process.
  In production: replace simulation
  with actual ML pipeline call.
  """

  import time
  import random

  with app.app_context():
    try:
      Start timer:
        start_time = datetime.utcnow()

      Simulate training work:
        time.sleep(30)
          â† Replace with actual ML training call
          â† e.g. ai_service.train_model()

      Simulate new metrics:
        new_accuracy  = round(
          random.uniform(88.0, 96.0), 2)
        new_precision = round(
          random.uniform(0.85, 0.96), 4)
        new_recall    = round(
          random.uniform(0.82, 0.94), 4)
        new_f1        = round(
          (2 * new_precision * new_recall) /
          (new_precision + new_recall), 4)

      Calculate duration:
        end_time = datetime.utcnow()
        duration = int(
          (end_time - start_time).total_seconds())

      Update training history:
        training = AiTrainingHistory.query.filter_by(
          id=training_id).first()
        If training:
          training.ended_at         = end_time
          training.duration_seconds = duration
          training.accuracy_after   = new_accuracy
          training.status           = 'success'
          training.notes = (
            f'Accuracy improved from '
            f'{training.accuracy_before}% '
            f'to {new_accuracy}%'
          )

      Update model status:
        model = AiModelStatus.get_current()
        If model:
          model.status          = 'active'
          model.accuracy        = new_accuracy
          model.precision_score = new_precision
          model.recall_score    = new_recall
          model.f1_score        = new_f1
          model.last_trained    = end_time
          model.updated_at      = end_time

          Bump version:
            old_ver = model.version or 'v1.0.0'
            parts   = old_ver.lstrip('v').split('.')
            parts[2] = str(int(parts[2]) + 1)
            model.version = 'v' + '.'.join(parts)

      Insert new feature importance rows:
        db.session.query(
          AiFeatureImportance
        ).delete()
          â† Clear old feature data

        FEATURE_NAMES = [
          'Sugar Level', 'Calories',
          'Disease Type', 'Protein',
          'User History', 'Time of Day',
          'Category', 'Fat Content'
        ]
        importances = sorted(
          [round(random.uniform(0.05,0.35),4)
            for _ in FEATURE_NAMES],
          reverse=True
        )
        for name, imp in zip(
          FEATURE_NAMES, importances):
          db.session.add(AiFeatureImportance(
            feature_name  = name,
            importance    = imp,
            model_version = model.version
          ))

      Commit all changes:
        db.session.commit()

    Except any Exception as e:
      Handle failure:
        try:
          training = AiTrainingHistory.query\
            .filter_by(id=training_id).first()
          if training:
            training.status = 'failed'
            training.notes  = str(e)
            training.ended_at = datetime.utcnow()

          model = AiModelStatus.get_current()
          if model:
            model.status     = 'degraded'
            model.updated_at = datetime.utcnow()

          db.session.commit()
        except:
          db.session.rollback()

        current_app.logger.error(
          f'[RETRAIN] Failed: {str(e)}')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - POST /retrain: SUPER_ADMIN ONLY
    use require_role() not require_min_role()
  - Background thread uses daemon=True
    so it dies if main process dies
  - Pass app._get_current_object() to thread
    NOT the proxy object â€” threading requires
    the real app instance
  - Simulation sleep(30) â€” replace with
    real ML pipeline in production
    Document this clearly in code comments
  - Feature importance rows: delete old ones
    then insert new ones per training cycle
  - Version bumping: patch version only
    (v1.0.0 â†’ v1.0.1 â†’ v1.0.2)
  - Background task failure must update
    training history AND model status
    Both or neither â€” never leave inconsistent
  - Polling endpoint is GET /ai/status â€”
    already built in Endpoint 1
    Frontend polls it every 10 seconds
    No separate polling endpoint needed
```

---
---

## ğŸ”· WEEK 3 DAY 4 â€” Reports Routes

```
Build Week 3 Day 4 reports & export routes for
Flask Admin Backend of Smart Canteen System.

All Week 1, Week 2, Week 3 Days 1-3 complete.

Day 4 covers ONLY:
  GET /api/admin/export/sales/preview
  GET /api/admin/export/sales
  GET /api/admin/export/health/preview
  GET /api/admin/export/health
  GET /api/admin/export/inventory/preview
  GET /api/admin/export/inventory

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ reports/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.reports.routes import reports_bp
  app.register_blueprint(reports_bp,
    url_prefix='/api/admin')

Also install:
  pip install reportlab

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BLUEPRINT + SHARED HELPERS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

reports_bp = Blueprint('reports', __name__)

All imports:
  from flask import (Blueprint, request,
    Response, stream_with_context)
  from flask_jwt_extended import jwt_required
  from datetime import datetime, date
  import csv, io
  from reportlab.lib.pagesizes import letter
  from reportlab.lib import colors
  from reportlab.platypus import (
    SimpleDocTemplate, Table,
    TableStyle, Paragraph, Spacer)
  from reportlab.lib.styles import
    getSampleStyleSheet
  from sqlalchemy import func
  from extensions import db
  from models import (Order, OrderItem, FoodItem,
    User, Inventory, AiRecommendationLog)
  from middleware import (require_min_role,
    log_export)
  from utils import (success, error,
    get_date_range_or_default,
    round_decimal, to_iso)

SHARED HELPERS:

def get_report_date_params():
  """
  Parse from/to date strings from request.args.
  Returns (from_dt, to_dt) datetime objects.
  """
  return get_date_range_or_default(
    request.args.get('from'),
    request.args.get('to'),
    default_days=30
  )

def make_csv_response(rows, headers, filename):
  """
  Build a streaming CSV response.
  Parameters:
    rows     â† list of lists (data rows)
    headers  â† list of column header strings
    filename â† download filename (no extension)
  Returns Flask Response with correct headers.
  """
  output = io.StringIO()
  writer = csv.writer(output)
  writer.writerow(headers)
  writer.writerows(rows)
  output.seek(0)

  today = date.today().strftime('%Y-%m-%d')
  fname = f'{filename}-{today}.csv'

  return Response(
    output.getvalue(),
    mimetype='text/csv',
    headers={
      'Content-Disposition':
        f'attachment; filename="{fname}"',
      'Content-Type':
        'text/csv; charset=utf-8'
    }
  )

def make_pdf_response(title, table_data,
                      headers, filename):
  """
  Build a PDF response using reportlab.
  Parameters:
    title      â† PDF title string
    table_data â† list of lists (data rows)
    headers    â† column header list
    filename   â† download filename (no extension)
  Returns Flask Response with PDF blob.
  """
  buffer = io.BytesIO()
  doc    = SimpleDocTemplate(buffer,
    pagesize=letter)
  styles = getSampleStyleSheet()
  story  = []

  story.append(
    Paragraph(title, styles['Title']))
  story.append(Spacer(1, 12))

  generated = Paragraph(
    f'Generated: {datetime.utcnow().strftime(
      "%d %b %Y %H:%M UTC")}',
    styles['Normal'])
  story.append(generated)
  story.append(Spacer(1, 20))

  table_content = [headers] + table_data
  table = Table(table_content)
  table.setStyle(TableStyle([
    ('BACKGROUND', (0,0), (-1,0),
      colors.HexColor('#111827')),
    ('TEXTCOLOR', (0,0), (-1,0),
      colors.whitesmoke),
    ('ALIGN', (0,0), (-1,-1), 'CENTER'),
    ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),
    ('FONTSIZE', (0,0), (-1,0), 11),
    ('BOTTOMPADDING', (0,0), (-1,0), 12),
    ('BACKGROUND', (0,1), (-1,-1),
      colors.HexColor('#f8fafc')),
    ('GRID', (0,0), (-1,-1), 0.5,
      colors.grey),
    ('FONTSIZE', (0,1), (-1,-1), 9),
    ('ROWBACKGROUNDS', (0,1), (-1,-1),
      [colors.white,
       colors.HexColor('#f1f5f9')])
  ]))
  story.append(table)
  doc.build(story)

  buffer.seek(0)
  today = date.today().strftime('%Y-%m-%d')
  fname = f'{filename}-{today}.pdf'

  return Response(
    buffer.getvalue(),
    mimetype='application/pdf',
    headers={
      'Content-Disposition':
        f'attachment; filename="{fname}"',
      'Content-Type': 'application/pdf'
    }
  )

def build_sales_data(from_dt, to_dt):
  """
  Core sales query reused by both preview
  and export endpoints.
  Returns list of dicts.
  """
  results = db.session.query(
    Order.order_number,
    User.name.label('customer'),
    func.count(OrderItem.id).label('items'),
    Order.total,
    Order.status,
    Order.payment_method,
    Order.created_at
  ).join(
    User, User.id == Order.user_id
  ).join(
    OrderItem, OrderItem.order_id == Order.id
  ).filter(
    Order.created_at.between(from_dt, to_dt)
  ).group_by(
    Order.order_number, User.name,
    Order.total, Order.status,
    Order.payment_method, Order.created_at
  ).order_by(
    Order.created_at.desc()
  ).all()

  return [{
    'order_number':   row.order_number,
    'customer':       row.customer,
    'items':          row.items,
    'total':          round_decimal(row.total),
    'status':         row.status,
    'payment_method': row.payment_method or 'N/A',
    'date':           row.created_at.strftime(
      '%d %b %Y %H:%M')
  } for row in results]

def build_health_data(from_dt, to_dt,
                      anonymize=False):
  """
  Core health/user query reused by preview
  and export endpoints.
  """
  users = User.query.filter_by(
    role='USER', status='active'
  ).all()

  rows = []
  for user in users:
    name  = 'Anonymous' if anonymize else user.name
    email = '***@***.com' if anonymize \
      else user.email
    rows.append({
      'name':       name,
      'email':      email,
      'risk_level': user.risk_level,
      'risk_score': user.risk_score,
      'conditions': ', '.join(
        user.conditions or []) or 'None',
      'dietary':    ', '.join(
        user.dietary_prefs or []) or 'None',
      'joined':     user.joined_at.strftime(
        '%d %b %Y') if user.joined_at else 'N/A'
    })
  return rows

def build_inventory_data():
  """
  Core inventory query reused by preview
  and export endpoints.
  """
  results = db.session.query(
    FoodItem.name,
    FoodItem.category,
    Inventory.current_stock,
    Inventory.reorder_level,
    Inventory.last_updated
  ).join(
    FoodItem,
    FoodItem.id == Inventory.food_id
  ).order_by(
    Inventory.current_stock.asc()
  ).all()

  return [{
    'name':          row.name,
    'category':      row.category,
    'current_stock': row.current_stock,
    'reorder_level': row.reorder_level,
    'status':
      'Out of Stock' if row.current_stock == 0
      else 'Low' if row.current_stock 
        row.reorder_level
      else 'Healthy',
    'last_updated':  row.last_updated.strftime(
      '%d %b %Y') if row.last_updated else 'N/A'
  } for row in results]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SALES ENDPOINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GET /api/admin/export/sales/preview
Auth: @jwt_required() + @require_min_role('ANALYST')

  from_dt, to_dt = get_report_date_params()
  data = build_sales_data(from_dt, to_dt)

  HEADERS = ['Order #','Customer','Items',
    'Total (â‚¹)','Status','Payment','Date']

  rows_as_arrays = [
    [d['order_number'], d['customer'],
     d['items'], d['total'], d['status'],
     d['payment_method'], d['date']]
    for d in data
  ]

  return success({
    'total_rows': len(data),
    'columns':    HEADERS,
    'rows':       rows_as_arrays[:10],
    'summary': {
      'date_range': (
        f'{from_dt.strftime("%d %b %Y")} '
        f'to {to_dt.strftime("%d %b %Y")}'),
      'generated_at': to_iso(datetime.utcnow())
    }
  }, 'Preview generated')

GET /api/admin/export/sales
Auth: @jwt_required() + @require_min_role('ANALYST')

  from_dt, to_dt = get_report_date_params()
  fmt  = request.args.get('format', 'csv')
  data = build_sales_data(from_dt, to_dt)

  HEADERS = ['Order #','Customer','Items',
    'Total (â‚¹)','Status','Payment','Date']
  rows = [
    [d['order_number'], d['customer'],
     d['items'], d['total'], d['status'],
     d['payment_method'], d['date']]
    for d in data
  ]

  log_export('sales_report', {
    'from': from_dt.isoformat(),
    'to':   to_dt.isoformat(),
    'format': fmt,
    'rows': len(rows)
  })

  If fmt == 'pdf':
    return make_pdf_response(
      'Sales Report', rows,
      HEADERS, 'sales-report')
  Else:
    return make_csv_response(
      rows, HEADERS, 'sales-report')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HEALTH ENDPOINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GET /api/admin/export/health/preview
Auth: @jwt_required() + @require_min_role('ANALYST')

  from_dt, to_dt = get_report_date_params()
  anonymize = request.args.get(
    'anonymize', 'false').lower() == 'true'
  data = build_health_data(
    from_dt, to_dt, anonymize)

  HEADERS = ['Name','Email','Risk Level',
    'Risk Score','Conditions',
    'Dietary Prefs','Joined']

  rows_as_arrays = [
    [d['name'], d['email'], d['risk_level'],
     d['risk_score'], d['conditions'],
     d['dietary'], d['joined']]
    for d in data
  ]

  return success({
    'total_rows': len(data),
    'columns':    HEADERS,
    'rows':       rows_as_arrays[:10],
    'summary': {
      'date_range': (
        f'{from_dt.strftime("%d %b %Y")} '
        f'to {to_dt.strftime("%d %b %Y")}'),
      'generated_at': to_iso(datetime.utcnow()),
      'anonymized':   anonymize
    }
  }, 'Preview generated')

GET /api/admin/export/health
Auth: @jwt_required() + @require_min_role('ANALYST')

  from_dt, to_dt = get_report_date_params()
  fmt = request.args.get('format', 'csv')
  anonymize = request.args.get(
    'anonymize','false').lower() == 'true'
  data = build_health_data(
    from_dt, to_dt, anonymize)

  HEADERS = ['Name','Email','Risk Level',
    'Risk Score','Conditions',
    'Dietary Prefs','Joined']
  rows = [
    [d['name'], d['email'], d['risk_level'],
     d['risk_score'], d['conditions'],
     d['dietary'], d['joined']]
    for d in data
  ]

  log_export('health_report', {
    'from':      from_dt.isoformat(),
    'to':        to_dt.isoformat(),
    'format':    fmt,
    'anonymize': anonymize,
    'rows':      len(rows)
  })

  If fmt == 'pdf':
    return make_pdf_response(
      'Health Trends Report', rows,
      HEADERS, 'health-report')
  Else:
    return make_csv_response(
      rows, HEADERS, 'health-report')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INVENTORY ENDPOINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GET /api/admin/export/inventory/preview
Auth: @jwt_required() + @require_min_role('ANALYST')

  data = build_inventory_data()

  HEADERS = ['Food Name','Category',
    'Current Stock','Reorder Level',
    'Status','Last Updated']

  rows_as_arrays = [
    [d['name'], d['category'],
     d['current_stock'], d['reorder_level'],
     d['status'], d['last_updated']]
    for d in data
  ]

  return success({
    'total_rows': len(data),
    'columns':    HEADERS,
    'rows':       rows_as_arrays[:10],
    'summary': {
      'generated_at': to_iso(datetime.utcnow()),
      'snapshot_date': to_iso(datetime.utcnow())
    }
  }, 'Preview generated')

GET /api/admin/export/inventory
Auth: @jwt_required() + @require_min_role('ANALYST')

  data = build_inventory_data()

  HEADERS = ['Food Name','Category',
    'Current Stock','Reorder Level',
    'Status','Last Updated']
  rows = [
    [d['name'], d['category'],
     d['current_stock'], d['reorder_level'],
     d['status'], d['last_updated']]
    for d in data
  ]

  log_export('inventory_report', {
    'rows': len(rows),
    'generated_at': datetime.utcnow().isoformat()
  })

  â† Inventory is CSV only (no PDF option)
  return make_csv_response(
    rows, HEADERS, 'inventory-report')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - build_*_data() functions shared between
    preview and export â€” never duplicate query
  - Preview: always returns first 10 rows only
    Full data only on actual export call
  - CSV uses io.StringIO â€” text buffer
    PDF uses io.BytesIO â€” binary buffer
  - log_export() called on EXPORT only
    not on preview â€” preview is read-only
  - Anonymize: replace name + email only
    risk data remains for health trends
  - Inventory export: CSV only, no PDF
    Sales + Health: both CSV and PDF
  - Response headers must include
    Content-Disposition with filename
    so browser triggers download dialog
  - reportlab TableStyle: alternate row colors
    for readability in exported PDFs
```

---
---

## ğŸ”· WEEK 3 DAY 5 â€” Audit Log Routes

```
Build Week 3 Day 5 audit log routes for
Flask Admin Backend of Smart Canteen System.

All Week 1, Week 2, Week 3 Days 1-4 complete.

Day 5 covers ONLY:
  GET /api/admin/audit/summary
  GET /api/admin/audit/admins
  GET /api/admin/audit

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FOLDER STRUCTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

backend/
â””â”€â”€ admin/
     â””â”€â”€ audit/
          â”œâ”€â”€ __init__.py
          â””â”€â”€ routes.py

Register in app.py:
  from admin.audit.routes import audit_bp
  app.register_blueprint(audit_bp,
    url_prefix='/api/admin')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BLUEPRINT SETUP:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

audit_bp = Blueprint('audit', __name__)

All imports:
  from flask import Blueprint, request
  from flask_jwt_extended import jwt_required
  from datetime import datetime, timedelta
  from sqlalchemy import func, or_, text
  from extensions import db
  from models import AuditLog, User
  from middleware import require_min_role
  from utils import (success, paginate_query,
    get_pagination_args, paginated,
    to_iso, to_relative_time,
    to_display_datetime)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 1 â€” GET /api/admin/audit/summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Logic:
  today_start = datetime.utcnow().replace(
    hour=0, minute=0, second=0, microsecond=0)

  Total actions all time:
    total_actions = AuditLog.query.count()

  Actions today:
    today_actions = AuditLog.query.filter(
      AuditLog.timestamp >= today_start
    ).count()

  Unique admins active today:
    active_admins = db.session.query(
      func.count(
        func.distinct(AuditLog.admin_id))
    ).filter(
      AuditLog.timestamp >= today_start,
      AuditLog.admin_id.isnot(None)
    ).scalar() or 0

  Last action timestamp:
    last_log = AuditLog.query.order_by(
      AuditLog.timestamp.desc()
    ).first()
    last_action_at = to_iso(
      last_log.timestamp) if last_log else None
    last_action_relative = to_relative_time(
      last_log.timestamp) if last_log else 'Never'

Response:
  return success({
    'total_actions':        total_actions,
    'today_actions':        today_actions,
    'active_admins_today':  active_admins,
    'last_action_at':       last_action_at,
    'last_action_relative': last_action_relative
  }, 'Audit summary retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 2 â€” GET /api/admin/audit/admins
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Purpose:
  Returns list of admins who have audit log
  entries. Used to populate the admin filter
  dropdown on the Audit Logs page.

Logic:
  results = db.session.query(
    User.id,
    User.name,
    User.role
  ).join(
    AuditLog,
    AuditLog.admin_id == User.id
  ).filter(
    AuditLog.admin_id.isnot(None)
  ).distinct().order_by(
    User.name.asc()
  ).all()

  admins = [{
    'id':   str(row.id),
    'name': row.name,
    'role': row.role
  } for row in results]

Response:
  return success({
    'admins': admins
  }, 'Admin list retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENDPOINT 3 â€” GET /api/admin/audit
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Auth: @jwt_required() + @require_min_role('ANALYST')

Query params (all optional):
  page       = int, default 1
  per_page   = int, default 20, max 100
  search     = string, full-text search
  admin_id   = UUID string
  action_type = string enum
  target_table = string
  ip         = string (partial match)
  from       = YYYY-MM-DD date string
  to         = YYYY-MM-DD date string

Logic:
  page, per_page = get_pagination_args()

  Base query with admin user joined:
    query = db.session.query(
      AuditLog
    ).options(
      db.joinedload(AuditLog.admin)
    ).order_by(
      AuditLog.timestamp.desc()
    )

  FILTER 1 â€” Full-text search:
    search = request.args.get(
      'search', '').strip()
    If search:
      query = query.filter(
        or_(
          AuditLog.summary.ilike(
            f'%{search}%'),
          AuditLog.target_table.ilike(
            f'%{search}%'),
          AuditLog.action_type.ilike(
            f'%{search}%'),
          AuditLog.ip_address.ilike(
            f'%{search}%'),
          func.cast(
            AuditLog.payload,
            db.Text
          ).ilike(f'%{search}%')
        )
      )

  FILTER 2 â€” Admin ID:
    admin_id = request.args.get('admin_id')
    If admin_id:
      Try to validate as UUID:
        from utils import validate_uuid
        if validate_uuid(admin_id):
          query = query.filter(
            AuditLog.admin_id == admin_id)

  FILTER 3 â€” Action type:
    action_type = request.args.get('action_type')
    VALID_ACTIONS = ['CREATE','UPDATE','DELETE',
      'LOGIN','LOGOUT','EXPORT',
      'RETRAIN','STATUS_CHANGE']
    If action_type and action_type in VALID_ACTIONS:
      query = query.filter(
        AuditLog.action_type == action_type)

  FILTER 4 â€” Target table:
    target_table = request.args.get('target_table')
    If target_table:
      query = query.filter(
        AuditLog.target_table == target_table)

  FILTER 5 â€” IP address (partial match):
    ip = request.args.get('ip', '').strip()
    If ip:
      query = query.filter(
        AuditLog.ip_address.ilike(f'%{ip}%'))

  FILTER 6 â€” Date range:
    from_str = request.args.get('from')
    to_str   = request.args.get('to')

    If from_str:
      Try datetime.strptime(from_str, '%Y-%m-%d')
      If valid: query = query.filter(
        AuditLog.timestamp >= from_dt)
      If invalid: ignore (do not error)

    If to_str:
      Try datetime.strptime(to_str, '%Y-%m-%d')
      If valid:
        to_dt_end = to_dt.replace(
          hour=23, minute=59, second=59)
          â† Include full day
        query = query.filter(
          AuditLog.timestamp <= to_dt_end)
      If invalid: ignore

  Paginate:
    items, meta = paginate_query(
      query, page, per_page)

  Build log items:
    def build_log_dict(log):
      admin_name = None
      admin_role = None
      admin_initials = None

      if log.admin:
        admin_name = log.admin.name
        admin_role = log.admin.role
        name_parts = log.admin.name.split()
        admin_initials = ''.join(
          p[0].upper()
          for p in name_parts[:2])

      return {
        'id':            str(log.id),
        'timestamp':     to_iso(log.timestamp),
        'timestamp_display':
          to_display_datetime(log.timestamp),
        'timestamp_relative':
          to_relative_time(log.timestamp),
        'admin_id':      str(log.admin_id)
          if log.admin_id else None,
        'admin_name':    admin_name,
        'admin_role':    admin_role,
        'admin_initials': admin_initials,
        'action_type':   log.action_type,
        'target_table':  log.target_table,
        'target_id':     log.target_id,
        'summary':       log.summary,
        'ip_address':    log.ip_address,
        'user_agent':    log.user_agent,
        'payload':       log.payload,
        'payload_before': log.payload_before,
        'payload_after':  log.payload_after
      }

    logs = [build_log_dict(log) for log in items]

Response:
  return paginated(logs, meta,
    'Audit logs retrieved')

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VERIFICATION â€” README_WEEK3.md:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test all Week 3 endpoints:

TOKEN = (SUPER_ADMIN login token)

Analytics:
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/summary?from=2025-01-01&to=2025-02-21"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/revenue-by-category?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/popular-foods?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/category-heatmap?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/peak-hours?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/disease-distribution"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/risk-trends?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/top-spenders?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/analytics/ai-impact?from=...&to=..."

AI Monitoring:
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/status"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/features"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/accuracy-history"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/logs?page=1&per_page=20"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/training-history"
  curl -X POST -H "Auth: Bearer $TOKEN"
    "/api/admin/ai/retrain"
    â† Must get 202 not 200
    â† status should change to 'retraining'
    â† Poll /ai/status every 10s
    â† After ~30s: status returns to 'active'

Reports:
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/export/sales/preview?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN" -o sales.csv
    "/api/admin/export/sales?from=...&to=..."
  curl -H "Auth: Bearer $TOKEN" -o sales.pdf
    "/api/admin/export/sales?format=pdf&from=...&to=..."
  Repeat for health and inventory exports

Audit Logs:
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/audit/summary"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/audit/admins"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/audit?page=1&per_page=20"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/audit?action_type=LOGIN"
  curl -H "Auth: Bearer $TOKEN"
    "/api/admin/audit?search=food"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RULES (ALL WEEK 3):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  - All analytics endpoints require date params
    default to last 30 days if absent
  - disease-distribution: NO date filter
    always reflects current user base
  - AI retrain: returns 202 Accepted not 200
    background task runs asynchronously
  - Retrain thread: daemon=True always
  - Reports: shared build_*_data() functions
    never duplicate the same query twice
  - Audit search: casts JSONB payload to
    Text for ILIKE â€” may be slow on large tables
    Add GIN index on payload in production
  - Audit date to filter: include full day
    by setting hour=23:59:59 on to_dt
  - Invalid filter values silently ignored
    never return 400 for bad filter params
    just omit that filter
  - paginate_query() used for all list endpoints
    in Week 3 â€” never raw .all() on large tables
```

---
